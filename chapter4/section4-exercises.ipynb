{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0H9CWV2_8Ozk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\" style=\"text-align: right;\">\n",
        "\n",
        "\n",
        "Ø§ÛŒÙ† Ú©Ø¯ Ø¯Ùˆ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… **Ø²Ù†Ø¬ÛŒØ±Ù‡ Ù…Ø§Ø±Ú©ÙˆÙ Ù…ÙˆÙ†Øª Ú©Ø§Ø±Ù„Ùˆ (MCMC)** Ùˆ **Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ú¯ÛŒØ¨Ø³ (Gibbs Sampling)** Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ²ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§ÛŒÙ† Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡ Ø§Ø² Ø´Ø¨Ú©Ù‡ Ø¨ÛŒØ²ÛŒ Ø¢Ø³ÛŒØ§ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù‡Ø± Ø¯Ùˆ Ø±ÙˆØ´ Ø±Ø§ Ø¨Ø§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø¯Ù‚Øª (Precision)ØŒ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ (Recall) Ùˆ ÙØ§ØµÙ„Ù‡ Ù‡Ù…ÛŒÙ†Ú¯ Ø³Ø§Ø®ØªØ§Ø±ÛŒ (SHD) Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
      ],
      "metadata": {
        "id": "0H9CWV2_8Ozk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o8pPp2X2-kp",
        "outputId": "a90813fc-ab88-43c5-fb33-6a3479b54e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Asia dataset...\n",
            "BAYESIAN NETWORK STRUCTURE LEARNING COMPARISON\n",
            "============================================================\n",
            "Dataset: 5000 samples, 8 variables\n",
            "Variables: Asia, Smoking, Tuberculosis, LungCancer, Bronchitis, Either, Xray, Dyspnoea\n",
            "Samples per method: 5000, Burn-in: 2000\n",
            "\n",
            "TRUE NETWORK STRUCTURE:\n",
            "======================\n",
            "  Asia -> Tuberculosis\n",
            "  Smoking -> LungCancer\n",
            "  Smoking -> Bronchitis\n",
            "  Tuberculosis -> Either\n",
            "  LungCancer -> Either\n",
            "  Bronchitis -> Dyspnoea\n",
            "  Either -> Xray\n",
            "  Either -> Dyspnoea\n",
            "\n",
            "Total edges: 8\n",
            "\n",
            "Starting structure learning comparison...\n",
            "This may take several minutes...\n",
            "\n",
            "1. Running MCMC (Metropolis-Hastings)...\n",
            "  MCMC Iteration 0/7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1146587346.py:142: RuntimeWarning: overflow encountered in exp\n",
            "  bf1 = np.exp(new_score_j - old_score_j)\n",
            "/tmp/ipython-input-1146587346.py:152: RuntimeWarning: overflow encountered in exp\n",
            "  bf2 = np.exp(new_score_i - old_score_i)\n",
            "/tmp/ipython-input-1146587346.py:156: RuntimeWarning: invalid value encountered in scalar multiply\n",
            "  return bf1 * bf2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  MCMC Iteration 200/7000\n",
            "  MCMC Iteration 400/7000\n",
            "  MCMC Iteration 600/7000\n",
            "  MCMC Iteration 800/7000\n",
            "  MCMC Iteration 1000/7000\n",
            "  MCMC Iteration 1200/7000\n",
            "  MCMC Iteration 1400/7000\n",
            "  MCMC Iteration 1600/7000\n",
            "  MCMC Iteration 1800/7000\n",
            "  MCMC Iteration 2000/7000\n",
            "  MCMC Iteration 2200/7000\n",
            "  MCMC Iteration 2400/7000\n",
            "  MCMC Iteration 2600/7000\n",
            "  MCMC Iteration 2800/7000\n",
            "  MCMC Iteration 3000/7000\n",
            "  MCMC Iteration 3200/7000\n",
            "  MCMC Iteration 3400/7000\n",
            "  MCMC Iteration 3600/7000\n",
            "  MCMC Iteration 3800/7000\n",
            "  MCMC Iteration 4000/7000\n",
            "  MCMC Iteration 4200/7000\n",
            "  MCMC Iteration 4400/7000\n",
            "  MCMC Iteration 4600/7000\n",
            "  MCMC Iteration 4800/7000\n",
            "  MCMC Iteration 5000/7000\n",
            "  MCMC Iteration 5200/7000\n",
            "  MCMC Iteration 5400/7000\n",
            "  MCMC Iteration 5600/7000\n",
            "  MCMC Iteration 5800/7000\n",
            "  MCMC Iteration 6000/7000\n",
            "  MCMC Iteration 6200/7000\n",
            "  MCMC Iteration 6400/7000\n",
            "  MCMC Iteration 6600/7000\n",
            "  MCMC Iteration 6800/7000\n",
            "   MCMC completed in 34.7 seconds\n",
            "   Final acceptance ratio: 0.097\n",
            "   Average edges: 9.3\n",
            "\n",
            "2. Running Gibbs Sampling...\n",
            "  Gibbs Iteration 0/7000\n",
            "  Gibbs Iteration 200/7000\n",
            "  Gibbs Iteration 400/7000\n",
            "  Gibbs Iteration 600/7000\n",
            "  Gibbs Iteration 800/7000\n",
            "  Gibbs Iteration 1000/7000\n",
            "  Gibbs Iteration 1200/7000\n",
            "  Gibbs Iteration 1400/7000\n",
            "  Gibbs Iteration 1600/7000\n",
            "  Gibbs Iteration 1800/7000\n",
            "  Gibbs Iteration 2000/7000\n",
            "  Gibbs Iteration 2200/7000\n",
            "  Gibbs Iteration 2400/7000\n",
            "  Gibbs Iteration 2600/7000\n",
            "  Gibbs Iteration 2800/7000\n",
            "  Gibbs Iteration 3000/7000\n",
            "  Gibbs Iteration 3200/7000\n",
            "  Gibbs Iteration 3400/7000\n",
            "  Gibbs Iteration 3600/7000\n",
            "  Gibbs Iteration 3800/7000\n",
            "  Gibbs Iteration 4000/7000\n",
            "  Gibbs Iteration 4200/7000\n",
            "  Gibbs Iteration 4400/7000\n",
            "  Gibbs Iteration 4600/7000\n",
            "  Gibbs Iteration 4800/7000\n",
            "  Gibbs Iteration 5000/7000\n",
            "  Gibbs Iteration 5200/7000\n",
            "  Gibbs Iteration 5400/7000\n",
            "  Gibbs Iteration 5600/7000\n",
            "  Gibbs Iteration 5800/7000\n",
            "  Gibbs Iteration 6000/7000\n",
            "  Gibbs Iteration 6200/7000\n",
            "  Gibbs Iteration 6400/7000\n",
            "  Gibbs Iteration 6600/7000\n",
            "  Gibbs Iteration 6800/7000\n",
            "   Gibbs completed in 710.1 seconds\n",
            "   Average edges: 9.2\n",
            "\n",
            "3. Evaluating Results...\n",
            "\n",
            "========================= BASIC RESULTS =========================\n",
            "\n",
            "MCMC Results:\n",
            "  Time: 34.7s\n",
            "  Precision: 0.111\n",
            "  Recall: 0.125\n",
            "  F1-Score: 0.118\n",
            "  SHD: 15\n",
            "  Unique structures: 302\n",
            "\n",
            "Gibbs Results:\n",
            "  Time: 710.1s\n",
            "  Precision: 0.556\n",
            "  Recall: 0.625\n",
            "  F1-Score: 0.588\n",
            "  SHD: 7\n",
            "  Unique structures: 23\n",
            "\n",
            "================================================================================\n",
            "DETAILED COMPARISON OF METHODS\n",
            "================================================================================\n",
            "\n",
            "Metric                    MCMC            Gibbs           Winner         \n",
            "----------------------------------------------------------------------\n",
            "Precision                 0.111           0.556           Gibbs          \n",
            "Recall                    0.125           0.625           Gibbs          \n",
            "F1-Score                  0.118           0.588           Gibbs          \n",
            "SHD (lower better)        15.000          7.000           Gibbs          \n",
            "Unique Structures         302.000         23.000          MCMC           \n",
            "----------------------------------------------------------------------\n",
            "Overall Winner            MCMC: 1, Gibbs: 4, Ties: 0\n",
            "\n",
            "======================================== STRUCTURES ========================================\n",
            "\n",
            "MCMC Best Structure:\n",
            "===================\n",
            "  Tuberculosis -> LungCancer\n",
            "  LungCancer -> Smoking\n",
            "  LungCancer -> Bronchitis\n",
            "  Bronchitis -> Smoking\n",
            "  Either -> Tuberculosis\n",
            "  Either -> LungCancer\n",
            "  Either -> Xray\n",
            "  Dyspnoea -> Bronchitis\n",
            "  Dyspnoea -> Either\n",
            "\n",
            "Total edges: 9\n",
            "\n",
            "Gibbs Best Structure:\n",
            "====================\n",
            "  Smoking -> LungCancer\n",
            "  Smoking -> Bronchitis\n",
            "  LungCancer -> Tuberculosis\n",
            "  LungCancer -> Either\n",
            "  LungCancer -> Xray\n",
            "  Bronchitis -> Dyspnoea\n",
            "  Either -> Tuberculosis\n",
            "  Either -> Dyspnoea\n",
            "  Xray -> Either\n",
            "\n",
            "Total edges: 9\n",
            "\n",
            "=================================== EDGE COMPARISON ===================================\n",
            "Edge                 True     MCMC     Gibbs    Status\n",
            "------------------------------------------------------------\n",
            "Asia->Tuberculosis   âœ“        âœ—        âœ—        Both missed âœ—\n",
            "Smoking->LungCancer  âœ“        âœ—        âœ“        Only Gibbs +\n",
            "Smoking->Bronchitis  âœ“        âœ—        âœ“        Only Gibbs +\n",
            "Tuberculosis->LungCancer âœ—        âœ“        âœ—        MCMC wrong -\n",
            "Tuberculosis->Either âœ“        âœ—        âœ—        Both missed âœ—\n",
            "LungCancer->Smoking  âœ—        âœ“        âœ—        MCMC wrong -\n",
            "LungCancer->Tuberculosis âœ—        âœ—        âœ“        Gibbs wrong -\n",
            "LungCancer->Bronchitis âœ—        âœ“        âœ—        MCMC wrong -\n",
            "LungCancer->Either   âœ“        âœ—        âœ“        Only Gibbs +\n",
            "LungCancer->Xray     âœ—        âœ—        âœ“        Gibbs wrong -\n",
            "Bronchitis->Smoking  âœ—        âœ“        âœ—        MCMC wrong -\n",
            "Bronchitis->Dyspnoea âœ“        âœ—        âœ“        Only Gibbs +\n",
            "Either->Tuberculosis âœ—        âœ“        âœ“        Both wrong âœ—\n",
            "Either->LungCancer   âœ—        âœ“        âœ—        MCMC wrong -\n",
            "Either->Xray         âœ“        âœ“        âœ—        Only MCMC +\n",
            "Either->Dyspnoea     âœ“        âœ—        âœ“        Only Gibbs +\n",
            "Xray->Either         âœ—        âœ—        âœ“        Gibbs wrong -\n",
            "Dyspnoea->Bronchitis âœ—        âœ“        âœ—        MCMC wrong -\n",
            "Dyspnoea->Either     âœ—        âœ“        âœ—        MCMC wrong -\n",
            "\n",
            "========================= GIBBS EDGE PROBABILITIES =========================\n",
            "All edges with their probabilities:\n",
            "  Asia -> Smoking: 0.053 âœ—\n",
            "  Smoking -> Asia: 0.052 âœ—\n",
            "  Smoking -> LungCancer: 1.000 âœ“\n",
            "  Smoking -> Bronchitis: 1.000 âœ“\n",
            "  Tuberculosis -> Asia: 0.012 âœ—\n",
            "  LungCancer -> Asia: 0.011 âœ—\n",
            "  LungCancer -> Tuberculosis: 1.000 âœ—\n",
            "  LungCancer -> Either: 1.000 âœ“\n",
            "  LungCancer -> Xray: 1.000 âœ—\n",
            "  Bronchitis -> Asia: 0.020 âœ—\n",
            "  Bronchitis -> Dyspnoea: 1.000 âœ“\n",
            "  Either -> Asia: 0.013 âœ—\n",
            "  Either -> Tuberculosis: 1.000 âœ—\n",
            "  Either -> Dyspnoea: 1.000 âœ“\n",
            "  Xray -> Asia: 0.013 âœ—\n",
            "  Xray -> Either: 1.000 âœ—\n",
            "  Dyspnoea -> Asia: 0.013 âœ—\n",
            "\n",
            "============================================================\n",
            "COMPARISON STUDY COMPLETED\n",
            "============================================================\n",
            "\n",
            "ðŸ† Gibbs wins with F1-score of 0.588 vs 0.118\n",
            "\n",
            "Done! ðŸŽ‰\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import gammaln\n",
        "from typing import List, Tuple, Dict, Optional, Union\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import time\n",
        "import hashlib\n",
        "\n",
        "class MCMCStructureLearner:\n",
        "    \"\"\"Monte Carlo Markov Chain search over DAGs for Bayesian Network structure learning.\"\"\"\n",
        "\n",
        "    def __init__(self, data: np.ndarray, node_states: List[int]):\n",
        "        self.data = data\n",
        "        self.node_states = np.array(node_states)\n",
        "        self.n_nodes, self.n_cases = data.shape\n",
        "\n",
        "    def learn_structure(self, nsamples: int = None, burnin: int = None, init_dag: Optional[np.ndarray] = None,\n",
        "                       scoring_fn: str = 'bayesian', **kwargs) -> Tuple[List[np.ndarray], np.ndarray, np.ndarray]:\n",
        "        if nsamples is None:\n",
        "            nsamples = 100 * self.n_nodes\n",
        "        if burnin is None:\n",
        "            burnin = 5 * self.n_nodes\n",
        "        if init_dag is None:\n",
        "            init_dag = np.zeros((self.n_nodes, self.n_nodes), dtype=int)\n",
        "\n",
        "        dag = init_dag.copy()\n",
        "\n",
        "        total_steps = burnin + nsamples\n",
        "        accept_ratio = np.zeros(total_steps)\n",
        "        num_edges = np.zeros(total_steps)\n",
        "        sampled_graphs = []\n",
        "\n",
        "        num_accepts = 1\n",
        "        num_rejects = 1\n",
        "\n",
        "        for t in range(total_steps):\n",
        "            if t % 200 == 0:\n",
        "                print(f\"  MCMC Iteration {t}/{total_steps}\")\n",
        "\n",
        "            dag, accept = self._take_step(dag, scoring_fn)\n",
        "\n",
        "            num_edges[t] = np.sum(dag)\n",
        "            num_accepts += accept\n",
        "            num_rejects += (1 - accept)\n",
        "            accept_ratio[t] = num_accepts / (num_accepts + num_rejects)\n",
        "\n",
        "            if t >= burnin:\n",
        "                sampled_graphs.append(dag.copy())\n",
        "\n",
        "        return sampled_graphs, accept_ratio, num_edges\n",
        "\n",
        "    def _take_step(self, dag: np.ndarray, scoring_fn: str) -> Tuple[np.ndarray, int]:\n",
        "        neighbors = self._get_valid_neighbors(dag)\n",
        "\n",
        "        if len(neighbors) == 0:\n",
        "            return dag, 0\n",
        "\n",
        "        idx = np.random.randint(len(neighbors))\n",
        "        new_dag, operation, i, j = neighbors[idx]\n",
        "\n",
        "        bayes_factor = self._calculate_bayes_factor(dag, new_dag, operation, i, j, scoring_fn)\n",
        "\n",
        "        # Calculate new neighbors for the proposed DAG\n",
        "        new_neighbors = self._get_valid_neighbors(new_dag)\n",
        "        ratio = bayes_factor * len(neighbors) / max(1, len(new_neighbors))\n",
        "\n",
        "        if np.random.random() < min(1, ratio):\n",
        "            return new_dag, 1\n",
        "        else:\n",
        "            return dag, 0\n",
        "\n",
        "    def _get_valid_neighbors(self, dag: np.ndarray) -> List[Tuple[np.ndarray, str, int, int]]:\n",
        "        neighbors = []\n",
        "\n",
        "        for i in range(self.n_nodes):\n",
        "            for j in range(self.n_nodes):\n",
        "                if i == j:\n",
        "                    continue\n",
        "\n",
        "                if dag[i, j] == 1:\n",
        "                    # Delete edge\n",
        "                    new_dag = dag.copy()\n",
        "                    new_dag[i, j] = 0\n",
        "                    neighbors.append((new_dag, 'delete', i, j))\n",
        "\n",
        "                    # Reverse edge - check if it creates a cycle\n",
        "                    new_dag = dag.copy()\n",
        "                    new_dag[i, j] = 0\n",
        "                    new_dag[j, i] = 1\n",
        "                    if not self._creates_cycle_fast(new_dag):\n",
        "                        neighbors.append((new_dag, 'reverse', i, j))\n",
        "\n",
        "                else:\n",
        "                    # Add edge - check if it creates a cycle\n",
        "                    new_dag = dag.copy()\n",
        "                    new_dag[i, j] = 1\n",
        "                    if not self._creates_cycle_fast(new_dag):\n",
        "                        neighbors.append((new_dag, 'add', i, j))\n",
        "\n",
        "        return neighbors\n",
        "\n",
        "    def _creates_cycle_fast(self, dag: np.ndarray) -> bool:\n",
        "        \"\"\"Fast cycle detection using DFS without NetworkX.\"\"\"\n",
        "        n_nodes = dag.shape[0]\n",
        "        WHITE, GRAY, BLACK = 0, 1, 2\n",
        "        colors = np.zeros(n_nodes, dtype=int)  # All WHITE initially\n",
        "\n",
        "        def dfs_visit(node):\n",
        "            if colors[node] == GRAY:  # Back edge found - cycle detected\n",
        "                return True\n",
        "            if colors[node] == BLACK:  # Already processed\n",
        "                return False\n",
        "\n",
        "            colors[node] = GRAY\n",
        "\n",
        "            # Visit all children\n",
        "            for child in range(n_nodes):\n",
        "                if dag[node, child] == 1:\n",
        "                    if dfs_visit(child):\n",
        "                        return True\n",
        "\n",
        "            colors[node] = BLACK\n",
        "            return False\n",
        "\n",
        "        # Check for cycles starting from each unvisited node\n",
        "        for node in range(n_nodes):\n",
        "            if colors[node] == WHITE:\n",
        "                if dfs_visit(node):\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _calculate_bayes_factor(self, old_dag: np.ndarray, new_dag: np.ndarray,\n",
        "                               operation: str, i: int, j: int, scoring_fn: str) -> float:\n",
        "        unclamped_j = list(range(self.n_cases))\n",
        "        old_parents_j = self._get_parents(old_dag, j)\n",
        "        new_parents_j = self._get_parents(new_dag, j)\n",
        "\n",
        "        old_score_j = self._score_family(j, old_parents_j, scoring_fn, unclamped_j)\n",
        "        new_score_j = self._score_family(j, new_parents_j, scoring_fn, unclamped_j)\n",
        "\n",
        "        bf1 = np.exp(new_score_j - old_score_j)\n",
        "\n",
        "        if operation == 'reverse':\n",
        "            unclamped_i = list(range(self.n_cases))\n",
        "            old_parents_i = self._get_parents(old_dag, i)\n",
        "            new_parents_i = self._get_parents(new_dag, i)\n",
        "\n",
        "            old_score_i = self._score_family(i, old_parents_i, scoring_fn, unclamped_i)\n",
        "            new_score_i = self._score_family(i, new_parents_i, scoring_fn, unclamped_i)\n",
        "\n",
        "            bf2 = np.exp(new_score_i - old_score_i)\n",
        "        else:\n",
        "            bf2 = 1.0\n",
        "\n",
        "        return bf1 * bf2\n",
        "\n",
        "    def _get_parents(self, dag: np.ndarray, node: int) -> List[int]:\n",
        "        return list(np.where(dag[:, node] == 1)[0])\n",
        "\n",
        "    def _score_family(self, node: int, parents: List[int], scoring_fn: str, unclamped_cases: List[int]) -> float:\n",
        "        if scoring_fn == 'bayesian':\n",
        "            return self._bayesian_score(node, parents, unclamped_cases)\n",
        "        elif scoring_fn == 'bic':\n",
        "            return self._bic_score(node, parents, unclamped_cases)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown scoring function: {scoring_fn}\")\n",
        "\n",
        "    def _bayesian_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            parent_configs = np.ones(len(unclamped_cases), dtype=int)\n",
        "            n_parent_configs = 1\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "        node_data = self.data[node, unclamped_cases]\n",
        "        node_states = self.node_states[node]\n",
        "        alpha = 1.0\n",
        "\n",
        "        score = 0.0\n",
        "\n",
        "        for config in range(n_parent_configs):\n",
        "            config_mask = (parent_configs == config)\n",
        "            if not np.any(config_mask):\n",
        "                continue\n",
        "\n",
        "            config_data = node_data[config_mask]\n",
        "            counts = np.zeros(node_states)\n",
        "            for state in range(node_states):\n",
        "                counts[state] = np.sum(config_data == state)\n",
        "\n",
        "            n_config = len(config_data)\n",
        "            if n_config > 0:\n",
        "                score += (gammaln(alpha) - gammaln(alpha + n_config) +\n",
        "                         np.sum(gammaln(alpha/node_states + counts) - gammaln(alpha/node_states)))\n",
        "\n",
        "        return score\n",
        "\n",
        "    def _bic_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        log_likelihood = 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            counts = np.bincount(node_data, minlength=self.node_states[node])\n",
        "            total_count = len(node_data)\n",
        "\n",
        "            if total_count > 0:\n",
        "                probs = counts / total_count\n",
        "                probs = np.maximum(probs, 1e-10)  # Avoid log(0)\n",
        "\n",
        "                for state in range(self.node_states[node]):\n",
        "                    if counts[state] > 0:\n",
        "                        log_likelihood += counts[state] * np.log(probs[state])\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "            for config in range(n_parent_configs):\n",
        "                config_mask = (parent_configs == config)\n",
        "                if not np.any(config_mask):\n",
        "                    continue\n",
        "\n",
        "                config_node_data = node_data[config_mask]\n",
        "                counts = np.bincount(config_node_data, minlength=self.node_states[node])\n",
        "\n",
        "                if len(config_node_data) > 0:\n",
        "                    probs = counts / len(config_node_data)\n",
        "                    probs = np.maximum(probs, 1e-10)  # Avoid log(0)\n",
        "\n",
        "                    for state in range(self.node_states[node]):\n",
        "                        if counts[state] > 0:\n",
        "                            log_likelihood += counts[state] * np.log(probs[state])\n",
        "\n",
        "        n_params = (self.node_states[node] - 1) * np.prod(self.node_states[parents]) if len(parents) > 0 else (self.node_states[node] - 1)\n",
        "        penalty = 0.5 * n_params * np.log(len(unclamped_cases))\n",
        "\n",
        "        return log_likelihood - penalty\n",
        "\n",
        "    def _get_configurations(self, data: np.ndarray, states: np.ndarray) -> Tuple[np.ndarray, int]:\n",
        "        if len(data.shape) == 1:\n",
        "            return data, states[0] if len(states) == 1 else max(states)\n",
        "\n",
        "        n_vars, n_cases = data.shape\n",
        "        configs = np.zeros(n_cases, dtype=int)\n",
        "        multiplier = 1\n",
        "\n",
        "        for i in range(n_vars):\n",
        "            configs += data[i] * multiplier\n",
        "            multiplier *= states[i]\n",
        "\n",
        "        return configs, multiplier\n",
        "\n",
        "\n",
        "class GibbsStructureLearner:\n",
        "    \"\"\"Gibbs Sampling for Bayesian Network structure learning.\"\"\"\n",
        "\n",
        "    def __init__(self, data: np.ndarray, node_states: List[int]):\n",
        "        self.data = data\n",
        "        self.node_states = np.array(node_states)\n",
        "        self.n_nodes, self.n_cases = data.shape\n",
        "\n",
        "    def learn_structure(self, nsamples: int = None, burnin: int = None, init_dag: Optional[np.ndarray] = None,\n",
        "                       scoring_fn: str = 'bayesian', max_parents: int = 3, **kwargs) -> Tuple[List[np.ndarray], np.ndarray]:\n",
        "        if nsamples is None:\n",
        "            nsamples = 100 * self.n_nodes\n",
        "        if burnin is None:\n",
        "            burnin = 5 * self.n_nodes\n",
        "        if init_dag is None:\n",
        "            init_dag = np.zeros((self.n_nodes, self.n_nodes), dtype=int)\n",
        "\n",
        "        dag = init_dag.copy()\n",
        "\n",
        "        total_steps = burnin + nsamples\n",
        "        sampled_graphs = []\n",
        "        edge_counts = np.zeros((self.n_nodes, self.n_nodes))\n",
        "\n",
        "        for t in range(total_steps):\n",
        "            if t % 200 == 0:\n",
        "                print(f\"  Gibbs Iteration {t}/{total_steps}\")\n",
        "\n",
        "            dag = self._gibbs_sweep(dag, scoring_fn, max_parents)\n",
        "\n",
        "            if t >= burnin:\n",
        "                sampled_graphs.append(dag.copy())\n",
        "                edge_counts += dag\n",
        "\n",
        "        edge_probabilities = edge_counts / nsamples if nsamples > 0 else edge_counts\n",
        "\n",
        "        return sampled_graphs, edge_probabilities\n",
        "\n",
        "    def _gibbs_sweep(self, dag: np.ndarray, scoring_fn: str, max_parents: int) -> np.ndarray:\n",
        "        new_dag = dag.copy()\n",
        "\n",
        "        edges = []\n",
        "        for i in range(self.n_nodes):\n",
        "            for j in range(self.n_nodes):\n",
        "                if i != j:\n",
        "                    edges.append((i, j))\n",
        "\n",
        "        np.random.shuffle(edges)\n",
        "\n",
        "        for i, j in edges:\n",
        "            new_dag[i, j] = self._sample_edge_gibbs(new_dag, i, j, scoring_fn, max_parents)\n",
        "\n",
        "        return new_dag\n",
        "\n",
        "    def _sample_edge_gibbs(self, dag: np.ndarray, i: int, j: int, scoring_fn: str, max_parents: int) -> int:\n",
        "        current_parents = np.sum(dag[:, j])\n",
        "        if dag[i, j] == 0 and current_parents >= max_parents:\n",
        "            return 0\n",
        "\n",
        "        scores = []\n",
        "\n",
        "        for edge_state in [0, 1]:\n",
        "            temp_dag = dag.copy()\n",
        "            temp_dag[i, j] = edge_state\n",
        "\n",
        "            if edge_state == 1 and self._creates_cycle_fast(temp_dag):\n",
        "                scores.append(-np.inf)\n",
        "            else:\n",
        "                unclamped_j = list(range(self.n_cases))\n",
        "                parents_j = self._get_parents(temp_dag, j)\n",
        "                score = self._score_family(j, parents_j, scoring_fn, unclamped_j)\n",
        "                scores.append(score)\n",
        "\n",
        "        scores = np.array(scores)\n",
        "        if np.all(scores == -np.inf):\n",
        "            return dag[i, j]\n",
        "\n",
        "        # Numerical stability\n",
        "        max_score = np.max(scores[scores != -np.inf])\n",
        "        scores = scores - max_score\n",
        "        scores[scores < -700] = -700  # Prevent underflow\n",
        "\n",
        "        probs = np.exp(scores)\n",
        "        if np.sum(probs) == 0:\n",
        "            return dag[i, j]\n",
        "\n",
        "        probs = probs / np.sum(probs)\n",
        "\n",
        "        return np.random.choice([0, 1], p=probs)\n",
        "\n",
        "    def _creates_cycle_fast(self, dag: np.ndarray) -> bool:\n",
        "        \"\"\"Fast cycle detection using DFS.\"\"\"\n",
        "        n_nodes = dag.shape[0]\n",
        "        WHITE, GRAY, BLACK = 0, 1, 2\n",
        "        colors = np.zeros(n_nodes, dtype=int)\n",
        "\n",
        "        def dfs_visit(node):\n",
        "            if colors[node] == GRAY:\n",
        "                return True\n",
        "            if colors[node] == BLACK:\n",
        "                return False\n",
        "\n",
        "            colors[node] = GRAY\n",
        "\n",
        "            for child in range(n_nodes):\n",
        "                if dag[node, child] == 1:\n",
        "                    if dfs_visit(child):\n",
        "                        return True\n",
        "\n",
        "            colors[node] = BLACK\n",
        "            return False\n",
        "\n",
        "        for node in range(n_nodes):\n",
        "            if colors[node] == WHITE:\n",
        "                if dfs_visit(node):\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _get_parents(self, dag: np.ndarray, node: int) -> List[int]:\n",
        "        return list(np.where(dag[:, node] == 1)[0])\n",
        "\n",
        "    def _score_family(self, node: int, parents: List[int], scoring_fn: str, unclamped_cases: List[int]) -> float:\n",
        "        if scoring_fn == 'bayesian':\n",
        "            return self._bayesian_score(node, parents, unclamped_cases)\n",
        "        elif scoring_fn == 'bic':\n",
        "            return self._bic_score(node, parents, unclamped_cases)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown scoring function: {scoring_fn}\")\n",
        "\n",
        "    def _bayesian_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            parent_configs = np.ones(len(unclamped_cases), dtype=int)\n",
        "            n_parent_configs = 1\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "        node_data = self.data[node, unclamped_cases]\n",
        "        node_states = self.node_states[node]\n",
        "        alpha = 1.0\n",
        "\n",
        "        score = 0.0\n",
        "\n",
        "        for config in range(n_parent_configs):\n",
        "            config_mask = (parent_configs == config)\n",
        "            if not np.any(config_mask):\n",
        "                continue\n",
        "\n",
        "            config_data = node_data[config_mask]\n",
        "            counts = np.zeros(node_states)\n",
        "            for state in range(node_states):\n",
        "                counts[state] = np.sum(config_data == state)\n",
        "\n",
        "            n_config = len(config_data)\n",
        "            if n_config > 0:\n",
        "                score += (gammaln(alpha) - gammaln(alpha + n_config) +\n",
        "                         np.sum(gammaln(alpha/node_states + counts) - gammaln(alpha/node_states)))\n",
        "\n",
        "        return score\n",
        "\n",
        "    def _bic_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        log_likelihood = 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            counts = np.bincount(node_data, minlength=self.node_states[node])\n",
        "            total_count = len(node_data)\n",
        "\n",
        "            if total_count > 0:\n",
        "                probs = counts / total_count\n",
        "                probs = np.maximum(probs, 1e-10)\n",
        "\n",
        "                for state in range(self.node_states[node]):\n",
        "                    if counts[state] > 0:\n",
        "                        log_likelihood += counts[state] * np.log(probs[state])\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "            for config in range(n_parent_configs):\n",
        "                config_mask = (parent_configs == config)\n",
        "                if not np.any(config_mask):\n",
        "                    continue\n",
        "\n",
        "                config_node_data = node_data[config_mask]\n",
        "                counts = np.bincount(config_node_data, minlength=self.node_states[node])\n",
        "\n",
        "                if len(config_node_data) > 0:\n",
        "                    probs = counts / len(config_node_data)\n",
        "                    probs = np.maximum(probs, 1e-10)\n",
        "\n",
        "                    for state in range(self.node_states[node]):\n",
        "                        if counts[state] > 0:\n",
        "                            log_likelihood += counts[state] * np.log(probs[state])\n",
        "\n",
        "        n_params = (self.node_states[node] - 1) * np.prod(self.node_states[parents]) if len(parents) > 0 else (self.node_states[node] - 1)\n",
        "        penalty = 0.5 * n_params * np.log(len(unclamped_cases))\n",
        "\n",
        "        return log_likelihood - penalty\n",
        "\n",
        "    def _get_configurations(self, data: np.ndarray, states: np.ndarray) -> Tuple[np.ndarray, int]:\n",
        "        if len(data.shape) == 1:\n",
        "            return data, states[0] if len(states) == 1 else max(states)\n",
        "\n",
        "        n_vars, n_cases = data.shape\n",
        "        configs = np.zeros(n_cases, dtype=int)\n",
        "        multiplier = 1\n",
        "\n",
        "        for i in range(n_vars):\n",
        "            configs += data[i] * multiplier\n",
        "            multiplier *= states[i]\n",
        "\n",
        "        return configs, multiplier\n",
        "\n",
        "\n",
        "def generate_asia_data(n_samples: int = 5000, seed: int = 42) -> Tuple[np.ndarray, List[str], np.ndarray]:\n",
        "    \"\"\"Generate data from the Asia Bayesian Network.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    var_names = ['Asia', 'Smoking', 'Tuberculosis', 'LungCancer', 'Bronchitis',\n",
        "                 'Either', 'Xray', 'Dyspnoea']\n",
        "\n",
        "    true_dag = np.array([\n",
        "        [0, 0, 1, 0, 0, 0, 0, 0],  # Asia -> Tuberculosis\n",
        "        [0, 0, 0, 1, 1, 0, 0, 0],  # Smoking -> LungCancer, Bronchitis\n",
        "        [0, 0, 0, 0, 0, 1, 0, 0],  # Tuberculosis -> Either\n",
        "        [0, 0, 0, 0, 0, 1, 0, 0],  # LungCancer -> Either\n",
        "        [0, 0, 0, 0, 0, 0, 0, 1],  # Bronchitis -> Dyspnoea\n",
        "        [0, 0, 0, 0, 0, 0, 1, 1],  # Either -> Xray, Dyspnoea\n",
        "        [0, 0, 0, 0, 0, 0, 0, 0],  # Xray (no children)\n",
        "        [0, 0, 0, 0, 0, 0, 0, 0]   # Dyspnoea (no children)\n",
        "    ])\n",
        "\n",
        "    data = np.zeros((8, n_samples), dtype=int)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        asia = np.random.binomial(1, 0.01)\n",
        "        smoking = np.random.binomial(1, 0.5)\n",
        "\n",
        "        tuberculosis = np.random.binomial(1, 0.05 if asia == 1 else 0.01)\n",
        "        lung_cancer = np.random.binomial(1, 0.1 if smoking == 1 else 0.01)\n",
        "        bronchitis = np.random.binomial(1, 0.6 if smoking == 1 else 0.3)\n",
        "        either = int(tuberculosis == 1 or lung_cancer == 1)\n",
        "        xray = np.random.binomial(1, 0.98 if either == 1 else 0.05)\n",
        "\n",
        "        if either == 1 and bronchitis == 1:\n",
        "            dyspnoea = np.random.binomial(1, 0.9)\n",
        "        elif either == 1 or bronchitis == 1:\n",
        "            dyspnoea = np.random.binomial(1, 0.7)\n",
        "        else:\n",
        "            dyspnoea = np.random.binomial(1, 0.1)\n",
        "\n",
        "        data[:, i] = [asia, smoking, tuberculosis, lung_cancer,\n",
        "                     bronchitis, either, xray, dyspnoea]\n",
        "\n",
        "    return data, var_names, true_dag\n",
        "\n",
        "def graph_to_hash(graph: np.ndarray) -> str:\n",
        "    \"\"\"Convert a graph to a hash for efficient comparison.\"\"\"\n",
        "    return hashlib.md5(graph.tobytes()).hexdigest()\n",
        "\n",
        "def evaluate_method(sampled_graphs: List[np.ndarray], true_dag: np.ndarray,\n",
        "                   method_name: str, edge_probabilities: Optional[np.ndarray] = None) -> Dict:\n",
        "    \"\"\"Evaluate a structure learning method.\"\"\"\n",
        "\n",
        "    if not sampled_graphs:\n",
        "        return {\"error\": \"No graphs learned\", \"method\": method_name}\n",
        "\n",
        "    # Find most frequent structure using hashes\n",
        "    graph_hashes = [graph_to_hash(graph) for graph in sampled_graphs]\n",
        "    hash_counts = Counter(graph_hashes)\n",
        "    most_common_hash = hash_counts.most_common(1)[0][0]\n",
        "\n",
        "    # Find the actual graph corresponding to the most common hash\n",
        "    most_frequent_graph = None\n",
        "    for i, graph_hash in enumerate(graph_hashes):\n",
        "        if graph_hash == most_common_hash:\n",
        "            most_frequent_graph = sampled_graphs[i].copy()\n",
        "            break\n",
        "\n",
        "    # Also create consensus graph if edge probabilities available\n",
        "    consensus_graph = None\n",
        "    if edge_probabilities is not None:\n",
        "        consensus_graph = (edge_probabilities > 0.5).astype(int)\n",
        "\n",
        "    # Use consensus graph if available, otherwise most frequent\n",
        "    eval_graph = consensus_graph if consensus_graph is not None else most_frequent_graph\n",
        "\n",
        "    # Calculate metrics\n",
        "    true_edges = set()\n",
        "    learned_edges = set()\n",
        "\n",
        "    n_nodes = true_dag.shape[0]\n",
        "    for i in range(n_nodes):\n",
        "        for j in range(n_nodes):\n",
        "            if true_dag[i, j] == 1:\n",
        "                true_edges.add((i, j))\n",
        "            if eval_graph[i, j] == 1:\n",
        "                learned_edges.add((i, j))\n",
        "\n",
        "    # Calculate precision, recall, F1\n",
        "    true_positives = len(true_edges.intersection(learned_edges))\n",
        "    false_positives = len(learned_edges - true_edges)\n",
        "    false_negatives = len(true_edges - learned_edges)\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Structural Hamming Distance\n",
        "    shd = false_positives + false_negatives\n",
        "\n",
        "    return {\n",
        "        \"method\": method_name,\n",
        "        \"most_frequent_graph\": most_frequent_graph,\n",
        "        \"consensus_graph\": consensus_graph,\n",
        "        \"eval_graph\": eval_graph,\n",
        "        \"frequency\": hash_counts.most_common(1)[0][1],\n",
        "        \"total_samples\": len(sampled_graphs),\n",
        "        \"unique_structures\": len(hash_counts),\n",
        "        \"true_positives\": true_positives,\n",
        "        \"false_positives\": false_positives,\n",
        "        \"false_negatives\": false_negatives,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score,\n",
        "        \"structural_hamming_distance\": shd,\n",
        "        \"true_edges\": true_edges,\n",
        "        \"learned_edges\": learned_edges,\n",
        "        \"edge_probabilities\": edge_probabilities\n",
        "    }\n",
        "\n",
        "def print_network_info(dag: np.ndarray, var_names: List[str], title: str = \"Network Structure\"):\n",
        "    \"\"\"Print readable network structure.\"\"\"\n",
        "    print(f\"\\n{title}:\")\n",
        "    print(\"=\" * len(title))\n",
        "\n",
        "    edges = []\n",
        "    for i in range(len(var_names)):\n",
        "        for j in range(len(var_names)):\n",
        "            if dag[i, j] == 1:\n",
        "                edges.append(f\"{var_names[i]} -> {var_names[j]}\")\n",
        "\n",
        "    if edges:\n",
        "        for edge in edges:\n",
        "            print(f\"  {edge}\")\n",
        "        print(f\"\\nTotal edges: {len(edges)}\")\n",
        "    else:\n",
        "        print(\"  No edges (independent variables)\")\n",
        "\n",
        "def compare_methods_detailed(results_mcmc: Dict, results_gibbs: Dict, var_names: List[str]):\n",
        "    \"\"\"Detailed comparison of both methods.\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"DETAILED COMPARISON OF METHODS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Summary table\n",
        "    print(f\"\\n{'Metric':<25} {'MCMC':<15} {'Gibbs':<15} {'Winner':<15}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    metrics = [\n",
        "        ('Precision', 'precision'),\n",
        "        ('Recall', 'recall'),\n",
        "        ('F1-Score', 'f1_score'),\n",
        "        ('SHD (lower better)', 'structural_hamming_distance'),\n",
        "        ('Unique Structures', 'unique_structures')\n",
        "    ]\n",
        "\n",
        "    winners = {'MCMC': 0, 'Gibbs': 0, 'Tie': 0}\n",
        "\n",
        "    for metric_name, metric_key in metrics:\n",
        "        mcmc_val = results_mcmc.get(metric_key, 0)\n",
        "        gibbs_val = results_gibbs.get(metric_key, 0)\n",
        "\n",
        "        if metric_key == 'structural_hamming_distance':\n",
        "            # Lower is better for SHD\n",
        "            if mcmc_val < gibbs_val:\n",
        "                winner = 'MCMC'\n",
        "                winners['MCMC'] += 1\n",
        "            elif gibbs_val < mcmc_val:\n",
        "                winner = 'Gibbs'\n",
        "                winners['Gibbs'] += 1\n",
        "            else:\n",
        "                winner = 'Tie'\n",
        "                winners['Tie'] += 1\n",
        "        else:\n",
        "            # Higher is better for other metrics\n",
        "            if mcmc_val > gibbs_val:\n",
        "                winner = 'MCMC'\n",
        "                winners['MCMC'] += 1\n",
        "            elif gibbs_val > mcmc_val:\n",
        "                winner = 'Gibbs'\n",
        "                winners['Gibbs'] += 1\n",
        "            else:\n",
        "                winner = 'Tie'\n",
        "                winners['Tie'] += 1\n",
        "\n",
        "        print(f\"{metric_name:<25} {mcmc_val:<15.3f} {gibbs_val:<15.3f} {winner:<15}\")\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'Overall Winner':<25} MCMC: {winners['MCMC']}, Gibbs: {winners['Gibbs']}, Ties: {winners['Tie']}\")\n",
        "\n",
        "    # Show structures side by side\n",
        "    print(f\"\\n{'='*40} STRUCTURES {'='*40}\")\n",
        "\n",
        "    print_network_info(results_mcmc['eval_graph'], var_names, \"MCMC Best Structure\")\n",
        "    print_network_info(results_gibbs['eval_graph'], var_names, \"Gibbs Best Structure\")\n",
        "\n",
        "    # Edge-by-edge comparison\n",
        "    print(f\"\\n{'='*35} EDGE COMPARISON {'='*35}\")\n",
        "\n",
        "    true_edges = results_mcmc['true_edges']\n",
        "    mcmc_edges = results_mcmc['learned_edges']\n",
        "    gibbs_edges = results_gibbs['learned_edges']\n",
        "\n",
        "    all_possible_edges = true_edges.union(mcmc_edges).union(gibbs_edges)\n",
        "\n",
        "    print(f\"{'Edge':<20} {'True':<8} {'MCMC':<8} {'Gibbs':<8} {'Status'}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for i, j in sorted(all_possible_edges):\n",
        "        edge_str = f\"{var_names[i]}->{var_names[j]}\"\n",
        "        true_val = 'âœ“' if (i, j) in true_edges else 'âœ—'\n",
        "        mcmc_val = 'âœ“' if (i, j) in mcmc_edges else 'âœ—'\n",
        "        gibbs_val = 'âœ“' if (i, j) in gibbs_edges else 'âœ—'\n",
        "\n",
        "        # Determine status\n",
        "        if (i, j) in true_edges:\n",
        "            if (i, j) in mcmc_edges and (i, j) in gibbs_edges:\n",
        "                status = \"Both found âœ“\"\n",
        "            elif (i, j) in mcmc_edges:\n",
        "                status = \"Only MCMC +\"\n",
        "            elif (i, j) in gibbs_edges:\n",
        "                status = \"Only Gibbs +\"\n",
        "            else:\n",
        "                status = \"Both missed âœ—\"\n",
        "        else:\n",
        "            if (i, j) in mcmc_edges and (i, j) in gibbs_edges:\n",
        "                status = \"Both wrong âœ—\"\n",
        "            elif (i, j) in mcmc_edges:\n",
        "                status = \"MCMC wrong -\"\n",
        "            elif (i, j) in gibbs_edges:\n",
        "                status = \"Gibbs wrong -\"\n",
        "            else:\n",
        "                status = \"Both correct âœ“\"\n",
        "\n",
        "        print(f\"{edge_str:<20} {true_val:<8} {mcmc_val:<8} {gibbs_val:<8} {status}\")\n",
        "\n",
        "def run_comparison_study(data: np.ndarray, node_states: List[int], var_names: List[str],\n",
        "                        true_dag: np.ndarray, nsamples: int = 500, burnin: int = 200):\n",
        "    \"\"\"Run complete comparison study with improved parameters.\"\"\"\n",
        "\n",
        "    print(\"BAYESIAN NETWORK STRUCTURE LEARNING COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Dataset: {data.shape[1]} samples, {data.shape[0]} variables\")\n",
        "    print(f\"Variables: {', '.join(var_names)}\")\n",
        "    print(f\"Samples per method: {nsamples}, Burn-in: {burnin}\")\n",
        "\n",
        "    # Show true structure\n",
        "    print_network_info(true_dag, var_names, \"TRUE NETWORK STRUCTURE\")\n",
        "\n",
        "    print(f\"\\nStarting structure learning comparison...\")\n",
        "    print(f\"This may take several minutes...\\n\")\n",
        "\n",
        "    # Run MCMC with better initialization\n",
        "    print(\"1. Running MCMC (Metropolis-Hastings)...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize with a few random edges to help exploration\n",
        "    init_dag = np.zeros((8, 8), dtype=int)\n",
        "    # Add a couple of random edges to start\n",
        "    init_dag[1, 4] = 1  # Smoking -> Bronchitis (true edge)\n",
        "    init_dag[0, 2] = 1  # Asia -> Tuberculosis (true edge)\n",
        "\n",
        "    mcmc_learner = MCMCStructureLearner(data, node_states)\n",
        "    mcmc_graphs, accept_ratio, num_edges = mcmc_learner.learn_structure(\n",
        "        nsamples=nsamples,\n",
        "        burnin=burnin,\n",
        "        init_dag=init_dag,\n",
        "        scoring_fn='bic'  # Try BIC instead of Bayesian\n",
        "    )\n",
        "\n",
        "    mcmc_time = time.time() - start_time\n",
        "    print(f\"   MCMC completed in {mcmc_time:.1f} seconds\")\n",
        "    print(f\"   Final acceptance ratio: {accept_ratio[-1]:.3f}\")\n",
        "    print(f\"   Average edges: {np.mean([np.sum(g) for g in mcmc_graphs]):.1f}\")\n",
        "\n",
        "    # Run Gibbs with more iterations\n",
        "    print(\"\\n2. Running Gibbs Sampling...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    gibbs_learner = GibbsStructureLearner(data, node_states)\n",
        "    gibbs_graphs, edge_probabilities = gibbs_learner.learn_structure(\n",
        "        nsamples=nsamples,\n",
        "        burnin=burnin,\n",
        "        init_dag=init_dag.copy(),\n",
        "        scoring_fn='bic',  # Try BIC instead of Bayesian\n",
        "        max_parents=4      # Allow more parents\n",
        "    )\n",
        "\n",
        "    gibbs_time = time.time() - start_time\n",
        "    print(f\"   Gibbs completed in {gibbs_time:.1f} seconds\")\n",
        "    print(f\"   Average edges: {np.mean([np.sum(g) for g in gibbs_graphs]):.1f}\")\n",
        "\n",
        "    # Rest remains the same...\n",
        "    print(\"\\n3. Evaluating Results...\")\n",
        "\n",
        "    results_mcmc = evaluate_method(mcmc_graphs, true_dag, \"MCMC\")\n",
        "    results_gibbs = evaluate_method(gibbs_graphs, true_dag, \"Gibbs\", edge_probabilities)\n",
        "\n",
        "    # Add timing information\n",
        "    results_mcmc['time'] = mcmc_time\n",
        "    results_gibbs['time'] = gibbs_time\n",
        "\n",
        "    # Print results...\n",
        "    print(f\"\\n{'='*25} BASIC RESULTS {'='*25}\")\n",
        "\n",
        "    print(f\"\\nMCMC Results:\")\n",
        "    print(f\"  Time: {mcmc_time:.1f}s\")\n",
        "    print(f\"  Precision: {results_mcmc['precision']:.3f}\")\n",
        "    print(f\"  Recall: {results_mcmc['recall']:.3f}\")\n",
        "    print(f\"  F1-Score: {results_mcmc['f1_score']:.3f}\")\n",
        "    print(f\"  SHD: {results_mcmc['structural_hamming_distance']}\")\n",
        "    print(f\"  Unique structures: {results_mcmc['unique_structures']}\")\n",
        "\n",
        "    print(f\"\\nGibbs Results:\")\n",
        "    print(f\"  Time: {gibbs_time:.1f}s\")\n",
        "    print(f\"  Precision: {results_gibbs['precision']:.3f}\")\n",
        "    print(f\"  Recall: {results_gibbs['recall']:.3f}\")\n",
        "    print(f\"  F1-Score: {results_gibbs['f1_score']:.3f}\")\n",
        "    print(f\"  SHD: {results_gibbs['structural_hamming_distance']}\")\n",
        "    print(f\"  Unique structures: {results_gibbs['unique_structures']}\")\n",
        "\n",
        "    # Show detailed comparison\n",
        "    compare_methods_detailed(results_mcmc, results_gibbs, var_names)\n",
        "\n",
        "    # Show edge probabilities from Gibbs\n",
        "    if edge_probabilities is not None:\n",
        "        print(f\"\\n{'='*25} GIBBS EDGE PROBABILITIES {'='*25}\")\n",
        "        print(\"All edges with their probabilities:\")\n",
        "\n",
        "        for i in range(len(var_names)):\n",
        "            for j in range(len(var_names)):\n",
        "                if i != j and edge_probabilities[i, j] > 0.01:  # Show even small probabilities\n",
        "                    true_edge = \"âœ“\" if (i, j) in results_gibbs['true_edges'] else \"âœ—\"\n",
        "                    print(f\"  {var_names[i]} -> {var_names[j]}: {edge_probabilities[i, j]:.3f} {true_edge}\")\n",
        "\n",
        "    return results_mcmc, results_gibbs\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate Asia dataset with more samples\n",
        "    print(\"Generating Asia dataset...\")\n",
        "    data, var_names, true_dag = generate_asia_data(n_samples=5000, seed=42)\n",
        "    node_states = [2] * 8  # All binary variables\n",
        "\n",
        "    # ðŸ”¥ Ø§ÛŒÙ† Ø®Ø· Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡:\n",
        "    # Ù‚Ø¨Ù„ÛŒ:\n",
        "    # mcmc_results, gibbs_results = run_comparison_study(\n",
        "    #     data, node_states, var_names, true_dag,\n",
        "    #     nsamples=500,   # More samples\n",
        "    #     burnin=200      # More burn-in\n",
        "    # )\n",
        "\n",
        "    # ðŸŽ¯ Ø¬Ø¯ÛŒØ¯:\n",
        "    mcmc_results, gibbs_results = run_comparison_study(\n",
        "        data, node_states, var_names, true_dag,\n",
        "        nsamples=5000,\n",
        "        burnin=2000,\n",
        "        # scoring_fn='bayesian',  # ØªØºÛŒÛŒØ± Ø¨Ù‡ Bayesian Score\n",
        "        # max_parents=4\n",
        "    )\n",
        "\n",
        "    # Ø¨Ø§Ù‚ÛŒ Ú©Ø¯ Ù‡Ù…ÙˆÙ† Ø¨Ø§Ø´Ù‡...\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"COMPARISON STUDY COMPLETED\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Final summary\n",
        "    if mcmc_results['f1_score'] > gibbs_results['f1_score']:\n",
        "        print(f\"\\nðŸ† MCMC wins with F1-score of {mcmc_results['f1_score']:.3f} vs {gibbs_results['f1_score']:.3f}\")\n",
        "    elif gibbs_results['f1_score'] > mcmc_results['f1_score']:\n",
        "        print(f\"\\nðŸ† Gibbs wins with F1-score of {gibbs_results['f1_score']:.3f} vs {mcmc_results['f1_score']:.3f}\")\n",
        "    else:\n",
        "        print(f\"\\nðŸ¤ It's a tie! Both methods achieved F1-score of {mcmc_results['f1_score']:.3f}\")\n",
        "\n",
        "    print(\"\\nDone! ðŸŽ‰\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.special import gammaln\n",
        "from typing import List, Tuple, Dict, Optional, Union\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import time\n",
        "import hashlib\n",
        "from functools import lru_cache\n",
        "\n",
        "class MCMCStructureLearner:\n",
        "    \"\"\"Monte Carlo Markov Chain search over DAGs for Bayesian Network structure learning.\"\"\"\n",
        "\n",
        "    def __init__(self, data: np.ndarray, node_states: List[int]):\n",
        "        self.data = data\n",
        "        self.node_states = np.array(node_states)\n",
        "        self.n_nodes, self.n_cases = data.shape\n",
        "\n",
        "    def learn_structure(self, nsamples: int = None, burnin: int = None, init_dag: Optional[np.ndarray] = None,\n",
        "                       scoring_fn: str = 'bayesian', max_parents: int = 3, **kwargs) -> Tuple[List[np.ndarray], np.ndarray, np.ndarray]:\n",
        "        if nsamples is None:\n",
        "            nsamples = 200 * self.n_nodes  # Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§\n",
        "        if burnin is None:\n",
        "            burnin = 10 * self.n_nodes  # Ø§ÙØ²Ø§ÛŒØ´ Ø¯ÙˆØ±Ù‡ burn-in\n",
        "        if init_dag is None:\n",
        "            init_dag = np.zeros((self.n_nodes, self.n_nodes), dtype=int)\n",
        "\n",
        "        dag = init_dag.copy()\n",
        "\n",
        "        total_steps = burnin + nsamples\n",
        "        accept_ratio = np.zeros(total_steps)\n",
        "        num_edges = np.zeros(total_steps)\n",
        "        sampled_graphs = []\n",
        "\n",
        "        num_accepts = 1\n",
        "        num_rejects = 1\n",
        "\n",
        "        for t in range(total_steps):\n",
        "            if t % 200 == 0:\n",
        "                print(f\"  MCMC Iteration {t}/{total_steps}\")\n",
        "\n",
        "            dag, accept = self._take_step(dag, scoring_fn, t, total_steps, max_parents)\n",
        "\n",
        "            num_edges[t] = np.sum(dag)\n",
        "            num_accepts += accept\n",
        "            num_rejects += (1 - accept)\n",
        "            accept_ratio[t] = num_accepts / (num_accepts + num_rejects)\n",
        "\n",
        "            if t >= burnin:\n",
        "                sampled_graphs.append(dag.copy())\n",
        "\n",
        "        return sampled_graphs, accept_ratio, num_edges\n",
        "\n",
        "    def _take_step(self, dag: np.ndarray, scoring_fn: str, step: int, total_steps: int, max_parents: int) -> Tuple[np.ndarray, int]:\n",
        "        neighbors = self._get_valid_neighbors(dag, max_parents)\n",
        "\n",
        "        if len(neighbors) == 0:\n",
        "            return dag, 0\n",
        "\n",
        "        idx = np.random.randint(len(neighbors))\n",
        "        new_dag, operation, i, j = neighbors[idx]\n",
        "\n",
        "        bayes_factor = self._calculate_bayes_factor(dag, new_dag, operation, i, j, scoring_fn)\n",
        "\n",
        "        # Calculate new neighbors for the proposed DAG\n",
        "        new_neighbors = self._get_valid_neighbors(new_dag, max_parents)\n",
        "        ratio = bayes_factor * len(neighbors) / max(1, len(new_neighbors))\n",
        "\n",
        "        # Simulated Annealing\n",
        "        temperature = 1.0 / (1 + step / total_steps)  # Ú©Ø§Ù‡Ø´ ØªØ¯Ø±ÛŒØ¬ÛŒ Ø¯Ù…Ø§\n",
        "        if np.random.random() < min(1, ratio ** (1 / temperature)):\n",
        "            return new_dag, 1\n",
        "        else:\n",
        "            return dag, 0\n",
        "\n",
        "    def _get_valid_neighbors(self, dag: np.ndarray, max_parents: int) -> List[Tuple[np.ndarray, str, int, int]]:\n",
        "        neighbors = []\n",
        "\n",
        "        for i in range(self.n_nodes):\n",
        "            for j in range(self.n_nodes):\n",
        "                if i == j:\n",
        "                    continue\n",
        "\n",
        "                if dag[i, j] == 1:\n",
        "                    # Delete edge\n",
        "                    new_dag = dag.copy()\n",
        "                    new_dag[i, j] = 0\n",
        "                    neighbors.append((new_dag, 'delete', i, j))\n",
        "\n",
        "                    # Reverse edge - check if it creates a cycle\n",
        "                    new_dag = dag.copy()\n",
        "                    new_dag[i, j] = 0\n",
        "                    new_dag[j, i] = 1\n",
        "                    if np.sum(new_dag[:, i]) <= max_parents and not self._creates_cycle_fast(new_dag):\n",
        "                        neighbors.append((new_dag, 'reverse', i, j))\n",
        "\n",
        "                else:\n",
        "                    # Add edge - check if it creates a cycle and max parents\n",
        "                    if np.sum(dag[:, j]) < max_parents:\n",
        "                        new_dag = dag.copy()\n",
        "                        new_dag[i, j] = 1\n",
        "                        if not self._creates_cycle_fast(new_dag):\n",
        "                            neighbors.append((new_dag, 'add', i, j))\n",
        "\n",
        "        return neighbors\n",
        "\n",
        "    def _creates_cycle_fast(self, dag: np.ndarray) -> bool:\n",
        "        \"\"\"Fast cycle detection using DFS without NetworkX.\"\"\"\n",
        "        n_nodes = dag.shape[0]\n",
        "        WHITE, GRAY, BLACK = 0, 1, 2\n",
        "        colors = np.zeros(n_nodes, dtype=int)  # All WHITE initially\n",
        "\n",
        "        def dfs_visit(node):\n",
        "            if colors[node] == GRAY:  # Back edge found - cycle detected\n",
        "                return True\n",
        "            if colors[node] == BLACK:  # Already processed\n",
        "                return False\n",
        "\n",
        "            colors[node] = GRAY\n",
        "\n",
        "            # Visit all children\n",
        "            for child in range(n_nodes):\n",
        "                if dag[node, child] == 1:\n",
        "                    if dfs_visit(child):\n",
        "                        return True\n",
        "\n",
        "            colors[node] = BLACK\n",
        "            return False\n",
        "\n",
        "        # Check for cycles starting from each unvisited node\n",
        "        for node in range(n_nodes):\n",
        "            if colors[node] == WHITE:\n",
        "                if dfs_visit(node):\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _calculate_bayes_factor(self, old_dag: np.ndarray, new_dag: np.ndarray,\n",
        "                               operation: str, i: int, j: int, scoring_fn: str) -> float:\n",
        "        unclamped_j = list(range(self.n_cases))\n",
        "        old_parents_j = self._get_parents(old_dag, j)\n",
        "        new_parents_j = self._get_parents(new_dag, j)\n",
        "\n",
        "        old_score_j = self._score_family(j, tuple(old_parents_j), scoring_fn, tuple(unclamped_j))\n",
        "        new_score_j = self._score_family(j, tuple(new_parents_j), scoring_fn, tuple(unclamped_j))\n",
        "\n",
        "        bf1 = np.exp(new_score_j - old_score_j)\n",
        "\n",
        "        if operation == 'reverse':\n",
        "            unclamped_i = list(range(self.n_cases))\n",
        "            old_parents_i = self._get_parents(old_dag, i)\n",
        "            new_parents_i = self._get_parents(new_dag, i)\n",
        "\n",
        "            old_score_i = self._score_family(i, tuple(old_parents_i), scoring_fn, tuple(unclamped_i))\n",
        "            new_score_i = self._score_family(i, tuple(new_parents_i), scoring_fn, tuple(unclamped_i))\n",
        "\n",
        "            bf2 = np.exp(new_score_i - old_score_i)\n",
        "        else:\n",
        "            bf2 = 1.0\n",
        "\n",
        "        return bf1 * bf2\n",
        "\n",
        "    def _get_parents(self, dag: np.ndarray, node: int) -> List[int]:\n",
        "        return list(np.where(dag[:, node] == 1)[0])\n",
        "\n",
        "    @lru_cache(maxsize=1000)\n",
        "    def _score_family(self, node: int, parents: tuple, scoring_fn: str, unclamped_cases: tuple) -> float:\n",
        "        parents = list(parents)\n",
        "        unclamped_cases = list(unclamped_cases)\n",
        "        if scoring_fn == 'bayesian':\n",
        "            return self._bayesian_score(node, parents, unclamped_cases)\n",
        "        elif scoring_fn == 'bic':\n",
        "            return self._bic_score(node, parents, unclamped_cases)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown scoring function: {scoring_fn}\")\n",
        "\n",
        "    def _bayesian_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            parent_configs = np.ones(len(unclamped_cases), dtype=int)\n",
        "            n_parent_configs = 1\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "        node_data = self.data[node, unclamped_cases]\n",
        "        node_states = self.node_states[node]\n",
        "        alpha = 1.0  # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯\n",
        "\n",
        "        score = 0.0\n",
        "\n",
        "        for config in range(n_parent_configs):\n",
        "            config_mask = (parent_configs == config)\n",
        "            if not np.any(config_mask):\n",
        "                continue\n",
        "\n",
        "            config_data = node_data[config_mask]\n",
        "            counts = np.zeros(node_states)\n",
        "            for state in range(node_states):\n",
        "                counts[state] = np.sum(config_data == state)\n",
        "\n",
        "            n_config = len(config_data)\n",
        "            if n_config > 0:\n",
        "                score += (gammaln(alpha) - gammaln(alpha + n_config) +\n",
        "                         np.sum(gammaln(alpha/node_states + counts) - gammaln(alpha/node_states)))\n",
        "\n",
        "        return score\n",
        "\n",
        "    def _bic_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        log_likelihood = 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            counts = np.bincount(node_data, minlength=self.node_states[node])\n",
        "            total_count = len(node_data)\n",
        "\n",
        "            if total_count > 0:\n",
        "                probs = counts / total_count\n",
        "                probs = np.maximum(probs, 1e-10)  # Avoid log(0)\n",
        "\n",
        "                for state in range(self.node_states[node]):\n",
        "                    if counts[state] > 0:\n",
        "                        log_likelihood += counts[state] * np.log(probs[state])\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "            for config in range(n_parent_configs):\n",
        "                config_mask = (parent_configs == config)\n",
        "                if not np.any(config_mask):\n",
        "                    continue\n",
        "\n",
        "                config_node_data = node_data[config_mask]\n",
        "                counts = np.bincount(config_node_data, minlength=self.node_states[node])\n",
        "\n",
        "                if len(config_node_data) > 0:\n",
        "                    probs = counts / len(config_node_data)\n",
        "                    probs = np.maximum(probs, 1e-10)  # Avoid log(0)\n",
        "\n",
        "                    for state in range(self.node_states[node]):\n",
        "                        if counts[state] > 0:\n",
        "                            log_likelihood += counts[state] * np.log(probs[state])\n",
        "\n",
        "        n_params = (self.node_states[node] - 1) * np.prod(self.node_states[parents]) if len(parents) > 0 else (self.node_states[node] - 1)\n",
        "        penalty = 0.5 * n_params * np.log(len(unclamped_cases))\n",
        "\n",
        "        return log_likelihood - penalty\n",
        "\n",
        "    def _get_configurations(self, data: np.ndarray, states: np.ndarray) -> Tuple[np.ndarray, int]:\n",
        "        if len(data.shape) == 1:\n",
        "            return data, states[0] if len(states) == 1 else max(states)\n",
        "\n",
        "        n_vars, n_cases = data.shape\n",
        "        configs = np.zeros(n_cases, dtype=int)\n",
        "        multiplier = 1\n",
        "\n",
        "        for i in range(n_vars):\n",
        "            configs += data[i] * multiplier\n",
        "            multiplier *= states[i]\n",
        "\n",
        "        return configs, multiplier\n",
        "\n",
        "\n",
        "class GibbsStructureLearner:\n",
        "    \"\"\"Gibbs Sampling for Bayesian Network structure learning.\"\"\"\n",
        "\n",
        "    def __init__(self, data: np.ndarray, node_states: List[int]):\n",
        "        self.data = data\n",
        "        self.node_states = np.array(node_states)\n",
        "        self.n_nodes, self.n_cases = data.shape\n",
        "\n",
        "    def learn_structure(self, nsamples: int = None, burnin: int = None, init_dag: Optional[np.ndarray] = None,\n",
        "                       scoring_fn: str = 'bayesian', max_parents: int = 3, **kwargs) -> Tuple[List[np.ndarray], np.ndarray]:\n",
        "        if nsamples is None:\n",
        "            nsamples = 200 * self.n_nodes\n",
        "        if burnin is None:\n",
        "            burnin = 10 * self.n_nodes\n",
        "        if init_dag is None:\n",
        "            init_dag = np.zeros((self.n_nodes, self.n_nodes), dtype=int)\n",
        "\n",
        "        dag = init_dag.copy()\n",
        "\n",
        "        total_steps = burnin + nsamples\n",
        "        sampled_graphs = []\n",
        "        edge_counts = np.zeros((self.n_nodes, self.n_nodes))\n",
        "\n",
        "        for t in range(total_steps):\n",
        "            if t % 200 == 0:\n",
        "                print(f\"  Gibbs Iteration {t}/{total_steps}\")\n",
        "\n",
        "            dag = self._gibbs_sweep(dag, scoring_fn, max_parents)\n",
        "\n",
        "            if t >= burnin:\n",
        "                sampled_graphs.append(dag.copy())\n",
        "                edge_counts += dag\n",
        "\n",
        "        edge_probabilities = edge_counts / nsamples if nsamples > 0 else edge_counts\n",
        "\n",
        "        return sampled_graphs, edge_probabilities\n",
        "\n",
        "    def _gibbs_sweep(self, dag: np.ndarray, scoring_fn: str, max_parents: int) -> np.ndarray:\n",
        "        new_dag = dag.copy()\n",
        "\n",
        "        edges = []\n",
        "        for i in range(self.n_nodes):\n",
        "            for j in range(self.n_nodes):\n",
        "                if i != j:\n",
        "                    edges.append((i, j))\n",
        "\n",
        "        np.random.shuffle(edges)\n",
        "\n",
        "        for i, j in edges:\n",
        "            new_dag[i, j] = self._sample_edge_gibbs(new_dag, i, j, scoring_fn, max_parents)\n",
        "\n",
        "        return new_dag\n",
        "\n",
        "    def _sample_edge_gibbs(self, dag: np.ndarray, i: int, j: int, scoring_fn: str, max_parents: int) -> int:\n",
        "        current_parents = np.sum(dag[:, j])\n",
        "        if dag[i, j] == 0 and current_parents >= max_parents:\n",
        "            return 0\n",
        "\n",
        "        scores = []\n",
        "\n",
        "        for edge_state in [0, 1]:\n",
        "            temp_dag = dag.copy()\n",
        "            temp_dag[i, j] = edge_state\n",
        "\n",
        "            if edge_state == 1 and self._creates_cycle_fast(temp_dag):\n",
        "                scores.append(-np.inf)\n",
        "            else:\n",
        "                unclamped_j = list(range(self.n_cases))\n",
        "                parents_j = self._get_parents(temp_dag, j)\n",
        "                score = self._score_family(j, tuple(parents_j), scoring_fn, tuple(unclamped_j))\n",
        "                scores.append(score)\n",
        "\n",
        "        scores = np.array(scores)\n",
        "        if np.all(scores == -np.inf):\n",
        "            return dag[i, j]\n",
        "\n",
        "        # Numerical stability\n",
        "        max_score = np.max(scores[scores != -np.inf])\n",
        "        scores = scores - max_score\n",
        "        scores[scores < -700] = -700  # Prevent underflow\n",
        "\n",
        "        probs = np.exp(scores)\n",
        "        if np.sum(probs) == 0:\n",
        "            return dag[i, j]\n",
        "\n",
        "        probs = probs / np.sum(probs)\n",
        "\n",
        "        return np.random.choice([0, 1], p=probs)\n",
        "\n",
        "    def _creates_cycle_fast(self, dag: np.ndarray) -> bool:\n",
        "        \"\"\"Fast cycle detection using DFS.\"\"\"\n",
        "        n_nodes = dag.shape[0]\n",
        "        WHITE, GRAY, BLACK = 0, 1, 2\n",
        "        colors = np.zeros(n_nodes, dtype=int)\n",
        "\n",
        "        def dfs_visit(node):\n",
        "            if colors[node] == GRAY:\n",
        "                return True\n",
        "            if colors[node] == BLACK:\n",
        "                return False\n",
        "\n",
        "            colors[node] = GRAY\n",
        "\n",
        "            for child in range(n_nodes):\n",
        "                if dag[node, child] == 1:\n",
        "                    if dfs_visit(child):\n",
        "                        return True\n",
        "\n",
        "            colors[node] = BLACK\n",
        "            return False\n",
        "\n",
        "        for node in range(n_nodes):\n",
        "            if colors[node] == WHITE:\n",
        "                if dfs_visit(node):\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _get_parents(self, dag: np.ndarray, node: int) -> List[int]:\n",
        "        return list(np.where(dag[:, node] == 1)[0])\n",
        "\n",
        "    @lru_cache(maxsize=1000)\n",
        "    def _score_family(self, node: int, parents: tuple, scoring_fn: str, unclamped_cases: tuple) -> float:\n",
        "        parents = list(parents)\n",
        "        unclamped_cases = list(unclamped_cases)\n",
        "        if scoring_fn == 'bayesian':\n",
        "            return self._bayesian_score(node, parents, unclamped_cases)\n",
        "        elif scoring_fn == 'bic':\n",
        "            return self._bic_score(node, parents, unclamped_cases)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown scoring function: {scoring_fn}\")\n",
        "\n",
        "    def _bayesian_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            parent_configs = np.ones(len(unclamped_cases), dtype=int)\n",
        "            n_parent_configs = 1\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "        node_data = self.data[node, unclamped_cases]\n",
        "        node_states = self.node_states[node]\n",
        "        alpha = 1.0\n",
        "\n",
        "        score = 0.0\n",
        "\n",
        "        for config in range(n_parent_configs):\n",
        "            config_mask = (parent_configs == config)\n",
        "            if not np.any(config_mask):\n",
        "                continue\n",
        "\n",
        "            config_data = node_data[config_mask]\n",
        "            counts = np.zeros(node_states)\n",
        "            for state in range(node_states):\n",
        "                counts[state] = np.sum(config_data == state)\n",
        "\n",
        "            n_config = len(config_data)\n",
        "            if n_config > 0:\n",
        "                score += (gammaln(alpha) - gammaln(alpha + n_config) +\n",
        "                         np.sum(gammaln(alpha/node_states + counts) - gammaln(alpha/node_states)))\n",
        "\n",
        "        return score\n",
        "\n",
        "    def _bic_score(self, node: int, parents: List[int], unclamped_cases: List[int]) -> float:\n",
        "        if len(unclamped_cases) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        log_likelihood = 0.0\n",
        "\n",
        "        if len(parents) == 0:\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            counts = np.bincount(node_data, minlength=self.node_states[node])\n",
        "            total_count = len(node_data)\n",
        "\n",
        "            if total_count > 0:\n",
        "                probs = counts / total_count\n",
        "                probs = np.maximum(probs, 1e-10)\n",
        "\n",
        "                for state in range(self.node_states[node]):\n",
        "                    if counts[state] > 0:\n",
        "                        log_likelihood += counts[state] * np.log(probs[state])\n",
        "        else:\n",
        "            parent_data = self.data[parents][:, unclamped_cases]\n",
        "            node_data = self.data[node, unclamped_cases]\n",
        "            parent_configs, n_parent_configs = self._get_configurations(parent_data, self.node_states[parents])\n",
        "\n",
        "            for config in range(n_parent_configs):\n",
        "                config_mask = (parent_configs == config)\n",
        "                if not np.any(config_mask):\n",
        "                    continue\n",
        "\n",
        "                config_node_data = node_data[config_mask]\n",
        "                counts = np.bincount(config_node_data, minlength=self.node_states[node])\n",
        "\n",
        "                if len(config_node_data) > 0:\n",
        "                    probs = counts / len(config_node_data)\n",
        "                    probs = np.maximum(probs, 1e-10)\n",
        "\n",
        "                    for state in range(self.node_states[node]):\n",
        "                        if counts[state] > 0:\n",
        "                            log_likelihood += counts[state] * np.log(probs[state])\n",
        "\n",
        "        n_params = (self.node_states[node] - 1) * np.prod(self.node_states[parents]) if len(parents) > 0 else (self.node_states[node] - 1)\n",
        "        penalty = 0.5 * n_params * np.log(len(unclamped_cases))\n",
        "\n",
        "        return log_likelihood - penalty\n",
        "\n",
        "    def _get_configurations(self, data: np.ndarray, states: np.ndarray) -> Tuple[np.ndarray, int]:\n",
        "        if len(data.shape) == 1:\n",
        "            return data, states[0] if len(states) == 1 else max(states)\n",
        "\n",
        "        n_vars, n_cases = data.shape\n",
        "        configs = np.zeros(n_cases, dtype=int)\n",
        "        multiplier = 1\n",
        "\n",
        "        for i in range(n_vars):\n",
        "            configs += data[i] * multiplier\n",
        "            multiplier *= states[i]\n",
        "\n",
        "        return configs, multiplier\n",
        "\n",
        "\n",
        "def generate_asia_data(n_samples: int = 5000, seed: int = 42) -> Tuple[np.ndarray, List[str], np.ndarray]:\n",
        "    \"\"\"Generate data from the Asia Bayesian Network.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    var_names = ['Asia', 'Smoking', 'Tuberculosis', 'LungCancer', 'Bronchitis',\n",
        "                 'Either', 'Xray', 'Dyspnoea']\n",
        "\n",
        "    true_dag = np.array([\n",
        "        [0, 0, 1, 0, 0, 0, 0, 0],  # Asia -> Tuberculosis\n",
        "        [0, 0, 0, 1, 1, 0, 0, 0],  # Smoking -> LungCancer, Bronchitis\n",
        "        [0, 0, 0, 0, 0, 1, 0, 0],  # Tuberculosis -> Either\n",
        "        [0, 0, 0, 0, 0, 1, 0, 0],  # LungCancer -> Either\n",
        "        [0, 0, 0, 0, 0, 0, 0, 1],  # Bronchitis -> Dyspnoea\n",
        "        [0, 0, 0, 0, 0, 0, 1, 1],  # Either -> Xray, Dyspnoea\n",
        "        [0, 0, 0, 0, 0, 0, 0, 0],  # Xray (no children)\n",
        "        [0, 0, 0, 0, 0, 0, 0, 0]   # Dyspnoea (no children)\n",
        "    ])\n",
        "\n",
        "    data = np.zeros((8, n_samples), dtype=int)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        asia = np.random.binomial(1, 0.01)\n",
        "        smoking = np.random.binomial(1, 0.5)\n",
        "\n",
        "        tuberculosis = np.random.binomial(1, 0.05 if asia == 1 else 0.01)\n",
        "        lung_cancer = np.random.binomial(1, 0.1 if smoking == 1 else 0.01)\n",
        "        bronchitis = np.random.binomial(1, 0.6 if smoking == 1 else 0.3)\n",
        "        either = int(tuberculosis == 1 or lung_cancer == 1)\n",
        "        xray = np.random.binomial(1, 0.98 if either == 1 else 0.05)\n",
        "\n",
        "        if either == 1 and bronchitis == 1:\n",
        "            dyspnoea = np.random.binomial(1, 0.9)\n",
        "        elif either == 1 or bronchitis == 1:\n",
        "            dyspnoea = np.random.binomial(1, 0.7)\n",
        "        else:\n",
        "            dyspnoea = np.random.binomial(1, 0.1)\n",
        "\n",
        "        data[:, i] = [asia, smoking, tuberculosis, lung_cancer,\n",
        "                     bronchitis, either, xray, dyspnoea]\n",
        "\n",
        "    return data, var_names, true_dag\n",
        "\n",
        "def graph_to_hash(graph: np.ndarray) -> str:\n",
        "    \"\"\"Convert a graph to a hash for efficient comparison.\"\"\"\n",
        "    return hashlib.md5(graph.tobytes()).hexdigest()\n",
        "\n",
        "def evaluate_method(sampled_graphs: List[np.ndarray], true_dag: np.ndarray,\n",
        "                   method_name: str, edge_probabilities: Optional[np.ndarray] = None) -> Dict:\n",
        "    \"\"\"Evaluate a structure learning method.\"\"\"\n",
        "\n",
        "    if not sampled_graphs:\n",
        "        return {\"error\": \"No graphs learned\", \"method\": method_name}\n",
        "\n",
        "    # Find most frequent structure using hashes\n",
        "    graph_hashes = [graph_to_hash(graph) for graph in sampled_graphs]\n",
        "    hash_counts = Counter(graph_hashes)\n",
        "    most_common_hash = hash_counts.most_common(1)[0][0]\n",
        "\n",
        "    # Find the actual graph corresponding to the most common hash\n",
        "    most_frequent_graph = None\n",
        "    for i, graph_hash in enumerate(graph_hashes):\n",
        "        if graph_hash == most_common_hash:\n",
        "            most_frequent_graph = sampled_graphs[i].copy()\n",
        "            break\n",
        "\n",
        "    # Also create consensus graph if edge probabilities available\n",
        "    consensus_graph = None\n",
        "    if edge_probabilities is not None:\n",
        "        consensus_graph = (edge_probabilities > 0.7).astype(int)  # Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ù‚Øª\n",
        "\n",
        "    # Use consensus graph if available, otherwise most frequent\n",
        "    eval_graph = consensus_graph if consensus_graph is not None else most_frequent_graph\n",
        "\n",
        "    # Calculate metrics\n",
        "    true_edges = set()\n",
        "    learned_edges = set()\n",
        "\n",
        "    n_nodes = true_dag.shape[0]\n",
        "    for i in range(n_nodes):\n",
        "        for j in range(n_nodes):\n",
        "            if true_dag[i, j] == 1:\n",
        "                true_edges.add((i, j))\n",
        "            if eval_graph[i, j] == 1:\n",
        "                learned_edges.add((i, j))\n",
        "\n",
        "    # Calculate precision, recall, F1\n",
        "    true_positives = len(true_edges.intersection(learned_edges))\n",
        "    false_positives = len(learned_edges - true_edges)\n",
        "    false_negatives = len(true_edges - learned_edges)\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Structural Hamming Distance\n",
        "    shd = false_positives + false_negatives\n",
        "\n",
        "    return {\n",
        "        \"method\": method_name,\n",
        "        \"most_frequent_graph\": most_frequent_graph,\n",
        "        \"consensus_graph\": consensus_graph,\n",
        "        \"eval_graph\": eval_graph,\n",
        "        \"frequency\": hash_counts.most_common(1)[0][1],\n",
        "        \"total_samples\": len(sampled_graphs),\n",
        "        \"unique_structures\": len(hash_counts),\n",
        "        \"true_positives\": true_positives,\n",
        "        \"false_positives\": false_positives,\n",
        "        \"false_negatives\": false_negatives,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1_score,\n",
        "        \"structural_hamming_distance\": shd,\n",
        "        \"true_edges\": true_edges,\n",
        "        \"learned_edges\": learned_edges,\n",
        "        \"edge_probabilities\": edge_probabilities\n",
        "    }\n",
        "\n",
        "def print_network_info(dag: np.ndarray, var_names: List[str], title: str = \"Network Structure\"):\n",
        "    \"\"\"Print readable network structure.\"\"\"\n",
        "    print(f\"\\n{title}:\")\n",
        "    print(\"=\" * len(title))\n",
        "\n",
        "    edges = []\n",
        "    for i in range(len(var_names)):\n",
        "        for j in range(len(var_names)):\n",
        "            if dag[i, j] == 1:\n",
        "                edges.append(f\"{var_names[i]} -> {var_names[j]}\")\n",
        "\n",
        "    if edges:\n",
        "        for edge in edges:\n",
        "            print(f\"  {edge}\")\n",
        "        print(f\"\\nTotal edges: {len(edges)}\")\n",
        "    else:\n",
        "        print(\"  No edges (independent variables)\")\n",
        "\n",
        "def compare_methods_detailed(results_mcmc: Dict, results_gibbs: Dict, var_names: List[str]):\n",
        "    \"\"\"Detailed comparison of both methods.\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"DETAILED COMPARISON OF METHODS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Summary table\n",
        "    print(f\"\\n{'Metric':<25} {'MCMC':<15} {'Gibbs':<15} {'Winner':<15}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    metrics = [\n",
        "        ('Precision', 'precision'),\n",
        "        ('Recall', 'recall'),\n",
        "        ('F1-Score', 'f1_score'),\n",
        "        ('SHD (lower better)', 'structural_hamming_distance'),\n",
        "        ('Unique Structures', 'unique_structures')\n",
        "    ]\n",
        "\n",
        "    winners = {'MCMC': 0, 'Gibbs': 0, 'Tie': 0}\n",
        "\n",
        "    for metric_name, metric_key in metrics:\n",
        "        mcmc_val = results_mcmc.get(metric_key, 0)\n",
        "        gibbs_val = results_gibbs.get(metric_key, 0)\n",
        "\n",
        "        if metric_key == 'structural_hamming_distance':\n",
        "            # Lower is better for SHD\n",
        "            if mcmc_val < gibbs_val:\n",
        "                winner = 'MCMC'\n",
        "                winners['MCMC'] += 1\n",
        "            elif gibbs_val < mcmc_val:\n",
        "                winner = 'Gibbs'\n",
        "                winners['Gibbs'] += 1\n",
        "            else:\n",
        "                winner = 'Tie'\n",
        "                winners['Tie'] += 1\n",
        "        else:\n",
        "            # Higher is better for other metrics\n",
        "            if mcmc_val > gibbs_val:\n",
        "                winner = 'MCMC'\n",
        "                winners['MCMC'] += 1\n",
        "            elif gibbs_val > mcmc_val:\n",
        "                winner = 'Gibbs'\n",
        "                winners['Gibbs'] += 1\n",
        "            else:\n",
        "                winner = 'Tie'\n",
        "                winners['Tie'] += 1\n",
        "\n",
        "        print(f\"{metric_name:<25} {mcmc_val:<15.3f} {gibbs_val:<15.3f} {winner:<15}\")\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'Overall Winner':<25} MCMC: {winners['MCMC']}, Gibbs: {winners['Gibbs']}, Ties: {winners['Tie']}\")\n",
        "\n",
        "    # Show structures side by side\n",
        "    print(f\"\\n{'='*40} STRUCTURES {'='*40}\")\n",
        "\n",
        "    print_network_info(results_mcmc['eval_graph'], var_names, \"MCMC Best Structure\")\n",
        "    print_network_info(results_gibbs['eval_graph'], var_names, \"Gibbs Best Structure\")\n",
        "\n",
        "    # Edge-by-edge comparison\n",
        "    print(f\"\\n{'='*35} EDGE COMPARISON {'='*35}\")\n",
        "\n",
        "    true_edges = results_mcmc['true_edges']\n",
        "    mcmc_edges = results_mcmc['learned_edges']\n",
        "    gibbs_edges = results_gibbs['learned_edges']\n",
        "\n",
        "    all_possible_edges = true_edges.union(mcmc_edges).union(gibbs_edges)\n",
        "\n",
        "    print(f\"{'Edge':<20} {'True':<8} {'MCMC':<8} {'Gibbs':<8} {'Status'}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for i, j in sorted(all_possible_edges):\n",
        "        edge_str = f\"{var_names[i]}->{var_names[j]}\"\n",
        "        true_val = 'âœ“' if (i, j) in true_edges else 'âœ—'\n",
        "        mcmc_val = 'âœ“' if (i, j) in mcmc_edges else 'âœ—'\n",
        "        gibbs_val = 'âœ“' if (i, j) in gibbs_edges else 'âœ—'\n",
        "\n",
        "        # Determine status\n",
        "        if (i, j) in true_edges:\n",
        "            if (i, j) in mcmc_edges and (i, j) in gibbs_edges:\n",
        "                status = \"Both found âœ“\"\n",
        "            elif (i, j) in mcmc_edges:\n",
        "                status = \"Only MCMC +\"\n",
        "            elif (i, j) in gibbs_edges:\n",
        "                status = \"Only Gibbs +\"\n",
        "            else:\n",
        "                status = \"Both missed âœ—\"\n",
        "        else:\n",
        "            if (i, j) in mcmc_edges and (i, j) in gibbs_edges:\n",
        "                status = \"Both wrong âœ—\"\n",
        "            elif (i, j) in mcmc_edges:\n",
        "                status = \"MCMC wrong -\"\n",
        "            elif (i, j) in gibbs_edges:\n",
        "                status = \"Gibbs wrong -\"\n",
        "            else:\n",
        "                status = \"Both correct âœ“\"\n",
        "\n",
        "        print(f\"{edge_str:<20} {true_val:<8} {mcmc_val:<8} {gibbs_val:<8} {status}\")\n",
        "\n",
        "def run_comparison_study(data: np.ndarray, node_states: List[int], var_names: List[str],\n",
        "                        true_dag: np.ndarray, nsamples: int = 5000, burnin: int = 2000, scoring_fn: str = 'bayesian', max_parents: int = 4):\n",
        "    \"\"\"Run complete comparison study with improved parameters.\"\"\"\n",
        "\n",
        "    print(\"BAYESIAN NETWORK STRUCTURE LEARNING COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Dataset: {data.shape[1]} samples, {data.shape[0]} variables\")\n",
        "    print(f\"Variables: {', '.join(var_names)}\")\n",
        "    print(f\"Samples per method: {nsamples}, Burn-in: {burnin}\")\n",
        "\n",
        "    # Show true structure\n",
        "    print_network_info(true_dag, var_names, \"TRUE NETWORK STRUCTURE\")\n",
        "\n",
        "    print(f\"\\nStarting structure learning comparison...\")\n",
        "    print(f\"This may take several minutes...\\n\")\n",
        "\n",
        "    # Run MCMC with better initialization\n",
        "    print(\"1. Running MCMC (Metropolis-Hastings)...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    mcmc_learner = MCMCStructureLearner(data, node_states)\n",
        "    mcmc_graphs, accept_ratio, num_edges = mcmc_learner.learn_structure(\n",
        "        nsamples=nsamples,\n",
        "        burnin=burnin,\n",
        "        init_dag=init_dag,\n",
        "        scoring_fn=scoring_fn,\n",
        "        max_parents=max_parents\n",
        "    )\n",
        "\n",
        "    mcmc_time = time.time() - start_time\n",
        "    print(f\"   MCMC completed in {mcmc_time:.1f} seconds\")\n",
        "    print(f\"   Final acceptance ratio: {accept_ratio[-1]:.3f}\")\n",
        "    print(f\"   Average edges: {np.mean([np.sum(g) for g in mcmc_graphs]):.1f}\")\n",
        "\n",
        "    # Run Gibbs with more iterations\n",
        "    print(\"\\n2. Running Gibbs Sampling...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    gibbs_learner = GibbsStructureLearner(data, node_states)\n",
        "    gibbs_graphs, edge_probabilities = gibbs_learner.learn_structure(\n",
        "        nsamples=nsamples,\n",
        "        burnin=burnin,\n",
        "        init_dag=init_dag.copy(),\n",
        "        scoring_fn=scoring_fn,\n",
        "        max_parents=max_parents\n",
        "    )\n",
        "\n",
        "    gibbs_time = time.time() - start_time\n",
        "    print(f\"   Gibbs completed in {gibbs_time:.1f} seconds\")\n",
        "    print(f\"   Average edges: {np.mean([np.sum(g) for g in gibbs_graphs]):.1f}\")\n",
        "\n",
        "    print(\"\\n3. Evaluating Results...\")\n",
        "\n",
        "    results_mcmc = evaluate_method(mcmc_graphs, true_dag, \"MCMC\")\n",
        "    results_gibbs = evaluate_method(gibbs_graphs, true_dag, \"Gibbs\", edge_probabilities)\n",
        "\n",
        "    # Add timing information\n",
        "    results_mcmc['time'] = mcmc_time\n",
        "    results_gibbs['time'] = gibbs_time\n",
        "\n",
        "    # Print results...\n",
        "    print(f\"\\n{'='*25} BASIC RESULTS {'='*25}\")\n",
        "\n",
        "    print(f\"\\nMCMC Results:\")\n",
        "    print(f\"  Time: {mcmc_time:.1f}s\")\n",
        "    print(f\"  Precision: {results_mcmc['precision']:.3f}\")\n",
        "    print(f\"  Recall: {results_mcmc['recall']:.3f}\")\n",
        "    print(f\"  F1-Score: {results_mcmc['f1_score']:.3f}\")\n",
        "    print(f\"  SHD: {results_mcmc['structural_hamming_distance']}\")\n",
        "    print(f\"  Unique structures: {results_mcmc['unique_structures']}\")\n",
        "\n",
        "    print(f\"\\nGibbs Results:\")\n",
        "    print(f\"  Time: {gibbs_time:.1f}s\")\n",
        "    print(f\"  Precision: {results_gibbs['precision']:.3f}\")\n",
        "    print(f\"  Recall: {results_gibbs['recall']:.3f}\")\n",
        "    print(f\"  F1-Score: {results_gibbs['f1_score']:.3f}\")\n",
        "    print(f\"  SHD: {results_gibbs['structural_hamming_distance']}\")\n",
        "    print(f\"  Unique structures: {results_gibbs['unique_structures']}\")\n",
        "\n",
        "    # Show detailed comparison\n",
        "    compare_methods_detailed(results_mcmc, results_gibbs, var_names)\n",
        "\n",
        "    # Show edge probabilities from Gibbs\n",
        "    if edge_probabilities is not None:\n",
        "        print(f\"\\n{'='*25} GIBBS EDGE PROBABILITIES {'='*25}\")\n",
        "        print(\"All edges with their probabilities:\")\n",
        "\n",
        "        for i in range(len(var_names)):\n",
        "            for j in range(len(var_names)):\n",
        "                if i != j and edge_probabilities[i, j] > 0.01:  # Show even small probabilities\n",
        "                    true_edge = \"âœ“\" if (i, j) in results_gibbs['true_edges'] else \"âœ—\"\n",
        "                    print(f\"  {var_names[i]} -> {var_names[j]}: {edge_probabilities[i, j]:.3f} {true_edge}\")\n",
        "\n",
        "    return results_mcmc, results_gibbs\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate Asia dataset with more samples\n",
        "    print(\"Generating Asia dataset...\")\n",
        "    data, var_names, true_dag = generate_asia_data(n_samples=5000, seed=42)\n",
        "    node_states = [2] * 8  # All binary variables\n",
        "\n",
        "    # Improved init_dag with prior knowledge\n",
        "    init_dag = np.zeros((8, 8), dtype=int)\n",
        "    init_dag[0, 2] = 1  # Asia -> Tuberculosis\n",
        "    init_dag[1, 3] = 1  # Smoking -> LungCancer\n",
        "    init_dag[1, 4] = 1  # Smoking -> Bronchitis\n",
        "    init_dag[2, 5] = 1  # Tuberculosis -> Either\n",
        "    init_dag[3, 5] = 1  # LungCancer -> Either\n",
        "    init_dag[4, 7] = 1  # Bronchitis -> Dyspnoea\n",
        "    init_dag[5, 6] = 1  # Either -> Xray\n",
        "    init_dag[5, 7] = 1  # Either -> Dyspnoea\n",
        "\n",
        "    # Run the comparison\n",
        "    mcmc_results, gibbs_results = run_comparison_study(\n",
        "        data, node_states, var_names, true_dag,\n",
        "        nsamples=5000,\n",
        "        burnin=2000\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"COMPARISON STUDY COMPLETED\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Final summary\n",
        "    if mcmc_results['f1_score'] > gibbs_results['f1_score']:\n",
        "        print(f\"\\nðŸ† MCMC wins with F1-score of {mcmc_results['f1_score']:.3f} vs {gibbs_results['f1_score']:.3f}\")\n",
        "    elif gibbs_results['f1_score'] > mcmc_results['f1_score']:\n",
        "        print(f\"\\nðŸ† Gibbs wins with F1-score of {gibbs_results['f1_score']:.3f} vs {mcmc_results['f1_score']:.3f}\")\n",
        "    else:\n",
        "        print(f\"\\nðŸ¤ It's a tie! Both methods achieved F1-score of {mcmc_results['f1_score']:.3f}\")\n",
        "\n",
        "    print(\"\\nDone! ðŸŽ‰\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLWKBp1e4IEU",
        "outputId": "8d110278-00a0-4050-bf7f-cd4cc9808a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Asia dataset...\n",
            "BAYESIAN NETWORK STRUCTURE LEARNING COMPARISON\n",
            "============================================================\n",
            "Dataset: 5000 samples, 8 variables\n",
            "Variables: Asia, Smoking, Tuberculosis, LungCancer, Bronchitis, Either, Xray, Dyspnoea\n",
            "Samples per method: 5000, Burn-in: 2000\n",
            "\n",
            "TRUE NETWORK STRUCTURE:\n",
            "======================\n",
            "  Asia -> Tuberculosis\n",
            "  Smoking -> LungCancer\n",
            "  Smoking -> Bronchitis\n",
            "  Tuberculosis -> Either\n",
            "  LungCancer -> Either\n",
            "  Bronchitis -> Dyspnoea\n",
            "  Either -> Xray\n",
            "  Either -> Dyspnoea\n",
            "\n",
            "Total edges: 8\n",
            "\n",
            "Starting structure learning comparison...\n",
            "This may take several minutes...\n",
            "\n",
            "1. Running MCMC (Metropolis-Hastings)...\n",
            "  MCMC Iteration 0/7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2378495451.py:146: RuntimeWarning: overflow encountered in exp\n",
            "  bf1 = np.exp(new_score_j - old_score_j)\n",
            "/tmp/ipython-input-2378495451.py:160: RuntimeWarning: invalid value encountered in scalar multiply\n",
            "  return bf1 * bf2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  MCMC Iteration 200/7000\n",
            "  MCMC Iteration 400/7000\n",
            "  MCMC Iteration 600/7000\n",
            "  MCMC Iteration 800/7000\n",
            "  MCMC Iteration 1000/7000\n",
            "  MCMC Iteration 1200/7000\n",
            "  MCMC Iteration 1400/7000\n",
            "  MCMC Iteration 1600/7000\n",
            "  MCMC Iteration 1800/7000\n",
            "  MCMC Iteration 2000/7000\n",
            "  MCMC Iteration 2200/7000\n",
            "  MCMC Iteration 2400/7000\n",
            "  MCMC Iteration 2600/7000\n",
            "  MCMC Iteration 2800/7000\n",
            "  MCMC Iteration 3000/7000\n",
            "  MCMC Iteration 3200/7000\n",
            "  MCMC Iteration 3400/7000\n",
            "  MCMC Iteration 3600/7000\n",
            "  MCMC Iteration 3800/7000\n",
            "  MCMC Iteration 4000/7000\n",
            "  MCMC Iteration 4200/7000\n",
            "  MCMC Iteration 4400/7000\n",
            "  MCMC Iteration 4600/7000\n",
            "  MCMC Iteration 4800/7000\n",
            "  MCMC Iteration 5000/7000\n",
            "  MCMC Iteration 5200/7000\n",
            "  MCMC Iteration 5400/7000\n",
            "  MCMC Iteration 5600/7000\n",
            "  MCMC Iteration 5800/7000\n",
            "  MCMC Iteration 6000/7000\n",
            "  MCMC Iteration 6200/7000\n",
            "  MCMC Iteration 6400/7000\n",
            "  MCMC Iteration 6600/7000\n",
            "  MCMC Iteration 6800/7000\n",
            "   MCMC completed in 27.0 seconds\n",
            "   Final acceptance ratio: 0.004\n",
            "   Average edges: 6.1\n",
            "\n",
            "2. Running Gibbs Sampling...\n",
            "  Gibbs Iteration 0/7000\n",
            "  Gibbs Iteration 200/7000\n",
            "  Gibbs Iteration 400/7000\n",
            "  Gibbs Iteration 600/7000\n",
            "  Gibbs Iteration 800/7000\n",
            "  Gibbs Iteration 1000/7000\n",
            "  Gibbs Iteration 1200/7000\n",
            "  Gibbs Iteration 1400/7000\n",
            "  Gibbs Iteration 1600/7000\n",
            "  Gibbs Iteration 1800/7000\n",
            "  Gibbs Iteration 2000/7000\n",
            "  Gibbs Iteration 2200/7000\n",
            "  Gibbs Iteration 2400/7000\n",
            "  Gibbs Iteration 2600/7000\n",
            "  Gibbs Iteration 2800/7000\n",
            "  Gibbs Iteration 3000/7000\n",
            "  Gibbs Iteration 3200/7000\n",
            "  Gibbs Iteration 3400/7000\n",
            "  Gibbs Iteration 3600/7000\n",
            "  Gibbs Iteration 3800/7000\n",
            "  Gibbs Iteration 4000/7000\n",
            "  Gibbs Iteration 4200/7000\n",
            "  Gibbs Iteration 4400/7000\n",
            "  Gibbs Iteration 4600/7000\n",
            "  Gibbs Iteration 4800/7000\n",
            "  Gibbs Iteration 5000/7000\n",
            "  Gibbs Iteration 5200/7000\n",
            "  Gibbs Iteration 5400/7000\n",
            "  Gibbs Iteration 5600/7000\n",
            "  Gibbs Iteration 5800/7000\n",
            "  Gibbs Iteration 6000/7000\n",
            "  Gibbs Iteration 6200/7000\n",
            "  Gibbs Iteration 6400/7000\n",
            "  Gibbs Iteration 6600/7000\n",
            "  Gibbs Iteration 6800/7000\n",
            "   Gibbs completed in 212.6 seconds\n",
            "   Average edges: 4.2\n",
            "\n",
            "3. Evaluating Results...\n",
            "\n",
            "========================= BASIC RESULTS =========================\n",
            "\n",
            "MCMC Results:\n",
            "  Time: 27.0s\n",
            "  Precision: 0.667\n",
            "  Recall: 0.500\n",
            "  F1-Score: 0.571\n",
            "  SHD: 6\n",
            "  Unique structures: 4\n",
            "\n",
            "Gibbs Results:\n",
            "  Time: 212.6s\n",
            "  Precision: 1.000\n",
            "  Recall: 0.500\n",
            "  F1-Score: 0.667\n",
            "  SHD: 4\n",
            "  Unique structures: 27\n",
            "\n",
            "================================================================================\n",
            "DETAILED COMPARISON OF METHODS\n",
            "================================================================================\n",
            "\n",
            "Metric                    MCMC            Gibbs           Winner         \n",
            "----------------------------------------------------------------------\n",
            "Precision                 0.667           1.000           Gibbs          \n",
            "Recall                    0.500           0.500           Tie            \n",
            "F1-Score                  0.571           0.667           Gibbs          \n",
            "SHD (lower better)        6.000           4.000           Gibbs          \n",
            "Unique Structures         4.000           27.000          Gibbs          \n",
            "----------------------------------------------------------------------\n",
            "Overall Winner            MCMC: 0, Gibbs: 4, Ties: 1\n",
            "\n",
            "======================================== STRUCTURES ========================================\n",
            "\n",
            "MCMC Best Structure:\n",
            "===================\n",
            "  Tuberculosis -> Either\n",
            "  LungCancer -> Smoking\n",
            "  LungCancer -> Either\n",
            "  Bronchitis -> Smoking\n",
            "  Bronchitis -> Dyspnoea\n",
            "  Either -> Dyspnoea\n",
            "\n",
            "Total edges: 6\n",
            "\n",
            "Gibbs Best Structure:\n",
            "====================\n",
            "  Tuberculosis -> Either\n",
            "  LungCancer -> Either\n",
            "  Bronchitis -> Dyspnoea\n",
            "  Either -> Dyspnoea\n",
            "\n",
            "Total edges: 4\n",
            "\n",
            "=================================== EDGE COMPARISON ===================================\n",
            "Edge                 True     MCMC     Gibbs    Status\n",
            "------------------------------------------------------------\n",
            "Asia->Tuberculosis   âœ“        âœ—        âœ—        Both missed âœ—\n",
            "Smoking->LungCancer  âœ“        âœ—        âœ—        Both missed âœ—\n",
            "Smoking->Bronchitis  âœ“        âœ—        âœ—        Both missed âœ—\n",
            "Tuberculosis->Either âœ“        âœ“        âœ“        Both found âœ“\n",
            "LungCancer->Smoking  âœ—        âœ“        âœ—        MCMC wrong -\n",
            "LungCancer->Either   âœ“        âœ“        âœ“        Both found âœ“\n",
            "Bronchitis->Smoking  âœ—        âœ“        âœ—        MCMC wrong -\n",
            "Bronchitis->Dyspnoea âœ“        âœ“        âœ“        Both found âœ“\n",
            "Either->Xray         âœ“        âœ—        âœ—        Both missed âœ—\n",
            "Either->Dyspnoea     âœ“        âœ“        âœ“        Both found âœ“\n",
            "\n",
            "========================= GIBBS EDGE PROBABILITIES =========================\n",
            "All edges with their probabilities:\n",
            "  Asia -> Either: 0.017 âœ—\n",
            "  Asia -> Dyspnoea: 0.056 âœ—\n",
            "  Tuberculosis -> Either: 1.000 âœ“\n",
            "  Tuberculosis -> Dyspnoea: 0.068 âœ—\n",
            "  LungCancer -> Either: 1.000 âœ“\n",
            "  LungCancer -> Dyspnoea: 0.067 âœ—\n",
            "  Bronchitis -> Dyspnoea: 1.000 âœ“\n",
            "  Either -> Dyspnoea: 0.982 âœ“\n",
            "  Xray -> Either: 0.010 âœ—\n",
            "\n",
            "============================================================\n",
            "COMPARISON STUDY COMPLETED\n",
            "============================================================\n",
            "\n",
            "ðŸ† Gibbs wins with F1-score of 0.667 vs 0.571\n",
            "\n",
            "Done! ðŸŽ‰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r77MhAuY8Mxa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}