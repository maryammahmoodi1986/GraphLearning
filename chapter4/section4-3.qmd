---
title: "۳-۴: الگوریتم Gibbs Sampling"
---
[قبلی](section4-2.qmd) | [بعدی](section4-4.qmd)


الگوریتم Gibbs Sampling یکی از روش‌های نمونه‌برداری بیزی پیشرفته است که در نسخه پایتون به کد اضافه شده و در نسخه اصلی MATLAB وجود نداشت. این روش با نمونه‌برداری شرطی از لبه‌های گراف، توزیع پسین ساختارها را تخمین می‌زند.

Gibbs Sampling به‌دلیل دقت بالا در شناسایی لبه‌های درست و حذف لبه‌های غیرضروری (به‌ویژه با آستانه بالا) برای داده‌های گسسته مناسب است. این روش از طریق بررسی منظم و شرطی تمام لبه‌های ممکن، به درک بهتری از ساختار شبکه می‌رسد.

## مراحل اصلی الگوریتم

 ۱. مقداردهی اولیه

مشابه MCMC، گراف اولیه با دانش پیشین (مانند لبه‌های شبکه Asia) یا به‌صورت خالی مقداردهی می‌شود. استفاده از دانش پیشین باعث می‌شود که الگوریتم از نقطه شروع مناسب‌تری آغاز کند و زمان همگرایی کاهش یابد.

این مقداردهی اولیه نقش مهمی در کیفیت نهایی نتایج دارد، زیرا Gibbs Sampling به‌تدریج ساختار را بهبود می‌بخشد بر اساس شرایط اولیه.

 ۲. نمونه‌برداری شرطی

در هر مرحله، تمام لبه‌های ممکن (به‌جز لبه‌های خودبه‌خود) به ترتیب تصادفی بررسی می‌شوند. این رویکرد سیستماتیک تضمین می‌کند که تمام روابط احتمالی مورد بررسی قرار گیرند.

برای هر لبه $(i,j)$، احتمال وجود یا عدم وجود لبه با استفاده از تابع امتیازدهی (مانند BDeu) محاسبه می‌شود. این محاسبات بر اساس وضعیت فعلی سایر لبه‌ها و داده‌های مشاهده شده انجام می‌گیرد.

لبه بر اساس این احتمالات نمونه‌برداری می‌شود، با شرط حفظ خاصیت غیرمدور بودن گراف. این محدودیت تضمین می‌کند که گراف نهایی قابل تفسیر و مناسب برای استنتاج علّی باشد.

 ۳. ساخت گراف اجماعی

پس از نمونه‌برداری، احتمال هر لبه محاسبه شده و گراف نهایی با آستانه‌ای (مانند ۰.۷) ساخته می‌شود. این آستانه باعث حذف لبه‌های با احتمال پایین می‌شود و تنها روابط قوی و قابل اعتماد در گراف نهایی باقی می‌مانند.

انتخاب آستانه مناسب یکی از مهم‌ترین تصمیمات در این روش است، زیرا آستانه بسیار بالا می‌تواند باعث از دست رفتن لبه‌های مهم شود.

 ۴. دوره Burn-in

مشابه MCMC، مراحل اولیه کنار گذاشته می‌شوند تا زنجیره به حالت پایدار برسد (۲۰۰۰ مرحله در اجرای اخیر). این دوره اطمینان می‌دهد که تأثیر شرایط اولیه از بین رفته و نمونه‌ها از توزیع پسین واقعی گرفته شده‌اند.

 ۵. جمع‌آوری نمونه‌ها

گراف‌های نمونه‌برداری شده پس از burn-in ذخیره می‌شوند تا توزیع پسین و احتمالات لبه‌ها تحلیل شوند. این مرحله امکان درک کامل از عدم‌قطعیت در ساختار شبکه را فراهم می‌کند.

 ۶. تحلیل احتمالات لبه‌ها

احتمالات لبه‌ها (مانند ۱.۰۰۰ برای Tuberculosis → Either) برای شناسایی روابط قوی استفاده می‌شوند. این اطلاعات کمک می‌کنند تا درجه اطمینان به هر رابطه تعیین شود.

## ویژگی‌ها و مزایا

 ۱. دقت بالا (Precision)

در اجرای اخیر، Precision به ۱.۰۰۰ رسید، زیرا هیچ لبه نادرستی اضافه نشد. این نشان‌دهنده قابلیت بالای این روش در تشخیص دقیق روابط واقعی است.

 ۲. مناسب برای داده‌های گسسته

به‌دلیل نمونه‌برداری شرطی، روابط قوی را با دقت بالا شناسایی می‌کند. این ویژگی باعث می‌شود که Gibbs Sampling برای مجموعه داده‌های گسسته عملکرد بهتری نسبت به روش‌های دیگر داشته باشد.

 ۳. تحلیل احتمالات لبه‌ها

ارائه احتمالات دقیق برای هر لبه، امکان تحلیل عمیق‌تر را فراهم می‌کند. این امکان به کاربران اجازه می‌دهد تا درجه اطمینان به هر رابطه را درک کرده و تصمیمات بهتری بگیرند.

 ۴. کاهش لبه‌های نادرست

با استفاده از آستانه مناسب، تعداد لبه‌های نادرست کاهش می‌یابد که منجر به بهبود کیفیت کلی مدل می‌شود.

## محدودیت‌های اصلی

 ۱. زمان اجرای طولانی

Gibbs Sampling بسیار کندتر از MCMC است (۲۱۲.۶ ثانیه در مقابل ۲۷.۰ ثانیه). این محدودیت مهم باعث می‌شود که این روش برای کاربردهای بزرگ‌مقیاس چالش‌برانگیز باشد.

 ۲. لبه‌های از دست رفته

لبه‌هایی مانند Tuberculosis → Asia و Xray → Either به‌دلیل آستانه بالا (۰.۷) شناسایی نشدند. این مشکل نشان‌دهنده حساسیت روش به تنظیمات پارامترهاست.

 ۳. حساسیت به آستانه

انتخاب آستانه نامناسب می‌تواند به حذف لبه‌های درست منجر شود. این مسئله نیاز به تنظیم دقیق و آزمایشات متعدد را ایجاد می‌کند.

 ۴. نیاز به تنظیم پارامتر

عملکرد الگوریتم بسیار وابسته به تنظیمات اولیه و پارامترهای مختلف است که تخصص و تجربه زیادی را می‌طلبد.

## بهبودهای اعمال شده

 ۱. آستانه گراف اجماعی

استفاده از آستانه ۰.۷ برای حذف لبه‌های غیرضروری. این تنظیم باعث بهبود قابل‌توجه در Precision شده است.

 ۲. دانش پیشین

مقداردهی اولیه با لبه‌های شناخته شده شبکه Asia. این بهبود کمک کرده تا الگوریتم سریع‌تر به ساختار مناسب همگرا شود.

 ۳. افزایش تعداد نمونه‌ها

۵۰۰۰ نمونه و ۲۰۰۰ burn-in برای همگرایی بهتر. این افزایش قابل‌توجه پایداری و کیفیت نتایج را بهبود بخشیده است.

 ۴. محدودیت حداکثر والدین

اعمال `max_parents=4` برای کاهش پیچیدگی گراف‌ها. این محدودیت از over-fitting جلوگیری کرده و تفسیرپذیری مدل را افزایش داده است.

 ۵. بهینه‌سازی محاسباتی

استفاده از کش کردن برای کاهش زمان محاسبات امتیازدهی. با وجود این بهینه‌سازی، همچنان زمان اجرا نسبت به سایر روش‌ها بالا است.

## نتایج اجرای اخیر

 معیارهای عملکرد

**Precision:** ۱.۰۰۰ (بهبود قابل‌توجه از ۰.۳۰۰)
**Recall:** ۰.۵۰۰ (بهبود از ۰.۳۷۵)
**F1-Score:** ۰.۶۶۷
**SHD (Structural Hamming Distance):** ۴ (کاهش از ۱۲)

 مشکلات شناسایی شده

لبه‌هایی مانند Tuberculosis → Asia، LungCancer → Smoking و Xray → Either به‌دلیل آستانه بالا از دست رفتند. این نشان‌دهنده نیاز به تنظیم دقیق‌تر آستانه یا استفاده از آستانه‌های متغیر است.

## مقایسه با سایر روش‌ها

نسبت به MCMC، Gibbs Sampling دقت بیشتری (Precision = 1.000) اما سرعت کمتری دارد. این تفاوت‌ها باید در انتخاب روش مناسب برای هر کاربرد در نظر گرفته شود.

## نتیجه‌گیری

الگوریتم Gibbs Sampling روشی قدرتمند و دقیق برای یادگیری ساختار شبکه‌های بیزی است که به‌ویژه برای کاربردهایی که دقت بالا اولویت دارد مناسب است. با وجود زمان اجرای طولانی، نتایج بسیار دقیق و قابل اعتمادی ارائه می‌دهد.

بهبودهای اعمال شده عملکرد این روش را به‌طور قابل‌توجهی افزایش داده‌اند، اما همچنان نیاز به تنظیم دقیق پارامترها و مدیریت زمان اجرا وجود دارد. برای کاربردهای عملی، توصیه می‌شود این روش با سایر الگوریتم‌ها ترکیب شود تا از مزایای هر کدام بهره‌برداری شود.

[قبلی](section4-2.qmd) | [بعدی](section4-4.qmd)
