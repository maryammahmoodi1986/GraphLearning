---
title: "۱-۴: تحلیل کد MCMC برای یادگیری ساختار شبکه‌های بیزی"
---
 [بعدی](section4-2.qmd)


فایل `learn_struct_mcmc.m` در کتابخانه BNT (Bayes Net Toolbox) برای یادگیری ساختار شبکه‌های بیزی (Bayesian Networks) با استفاده از روش زنجیره مارکوف مونت کارلو (MCMC) در محیط MATLAB طراحی شده است. این فایل برای نمونه‌برداری از گراف‌های جهت‌دار غیرمدور (DAGs) به‌منظور شناسایی ساختار بهینه شبکه بیزی بر اساس داده‌های ورودی استفاده می‌شود.

این روش از الگوریتم Metropolis-Hastings (یکی از روش‌های MCMC) در فضای گراف‌های جهت‌دار غیرمدور (DAGs) جستجو می‌کند تا توزیع پسین (posterior distribution) ساختارهای ممکن را تخمین بزند. این کار با نمونه‌برداری از گراف‌ها و ارزیابی آن‌ها بر اساس یک تابع امتیازدهی (مانند BDeu یا BIC) انجام می‌شود.

## کاربردهای کلیدی

۱. یادگیری ساختار شبکه بیزی
شناسایی روابط علی یا وابستگی‌ها بین متغیرها در داده‌ها. این کاربرد در تحلیل داده‌های پیچیده و شناسایی الگوهای پنهان در سیستم‌های مختلف بسیار مهم است.

 ۲. مدل‌سازی احتمالاتی
استفاده در حوزه‌هایی مانند هوش مصنوعی، یادگیری ماشین، زیست‌فناوری و تحلیل داده‌های پیچیده. این روش امکان مدل‌سازی عدم‌قطعیت و روابط پیچیده بین متغیرها را فراهم می‌کند.

۳. تحلیل داده‌های کاملاً مشاهده شده
این روش در حال حاضر فقط برای داده‌های کاملاً مشاهده شده (بدون متغیرهای مخفی) مناسب است، که آن را برای بسیاری از کاربردهای عملی قابل استفاده می‌سازد.

## مزایای کلیدی

۱. رویکرد بیزی جامع
برخلاف روش‌های نقطه‌ای (مانند K2)، این روش توزیع پسین گراف‌ها را تخمین می‌زند، که امکان تحلیل عدم‌قطعیت در ساختار را فراهم می‌کند. این ویژگی به‌ویژه در موارد پیچیده که عدم‌قطعیت زیادی وجود دارد، بسیار ارزشمند است.

۲. انعطاف‌پذیری بالا
قابلیت استفاده از توابع امتیازدهی مختلف (مانند BDeu یا BIC) به‌تناسب نوع داده و مسئله. این انعطاف‌پذیری امکان تطبیق روش با انواع مختلف مسائل را فراهم می‌کند.

۳. ساختار ماژولار
طراحی ماژولار در BNT امکان ادغام با سایر روش‌های یادگیری و استنتاج را فراهم می‌کند. این ویژگی امکان ترکیب روش‌های مختلف و استفاده از قابلیت‌های متنوع کتابخانه را می‌دهد.

## محدودیت‌های عمده

۱. زمان‌بر بودن محاسبات
برای شبکه‌های با بیش از ۱۰ گره، همگرایی MCMC ممکن است زمان‌بر باشد. این محدودیت استفاده از روش را در کاربردهای بزرگ‌مقیاس دشوار می‌سازد.

۲. محدودیت داده‌های کاملاً مشاهده شده
این روش در حال حاضر از داده‌های با متغیرهای مخفی پشتیبانی نمی‌کند. برای بسیاری از کاربردهای واقعی که شامل داده‌های ناقص هستند، این محدودیت مهم است.

۳. حساسیت به مقداردهی اولیه
عملکرد به‌شدت به گراف اولیه و پارامترهای نمونه‌برداری وابسته است. انتخاب نامناسب این پارامترها می‌تواند به نتایج ضعیف منجر شود.

## ورودی‌ها و خروجی‌ها

### ورودی‌های اصلی

**data:** ماتریس داده‌ها (اندازه: تعداد گره‌ها × تعداد نمونه‌ها). هر ستون یک نمونه داده و هر ردیف یک متغیر است. داده‌ها باید گسسته (discrete) و کاملاً مشاهده شده باشند.

**ns:** بردار تعداد حالت‌های ممکن برای هر گره (تعداد مقادیر گسسته برای هر متغیر).

### پارامترهای اختیاری (varargin)

**'nsamples':** تعداد نمونه‌های MCMC (پیش‌فرض: ۱۰۰).

**'burnin':** تعداد مراحل burn-in برای رسیدن به حالت پایدار (پیش‌فرض: ۱۰).

**سایر پارامترها:** مانند نوع تابع امتیازدهی یا گراف اولیه.

### خروجی‌های کلیدی

**sampled_graphs:** لیستی از گراف‌های نمونه‌برداری شده (DAG‌ها) به‌صورت ماتریس‌های مجاورت (adjacency matrices).

**accept_ratio:** بردار نرخ پذیرش (acceptance ratio) در هر مرحله از MCMC، که به‌عنوان معیاری برای تشخیص همگرایی استفاده می‌شود.

## توابع و اجزای اصلی

### مراحل اصلی الگوریتم

**۱. مقداردهی اولیه**
گراف اولیه (DAG) معمولاً به‌صورت تصادفی یا خالی مقداردهی می‌شود. اگر گراف اولیه ارائه نشود، یک گراف خالی (بدون لبه) استفاده می‌شود.

**۲. نمونه‌برداری با Metropolis-Hastings**
در هر مرحله، یک گراف جدید از طریق اعمال یکی از سه عملیات پیشنهاد می‌شود:
- افزودن لبه (add edge): افزودن یک لبه جدید بین دو گره، به‌شرطی که چرخه ایجاد نشود
- حذف لبه (delete edge): حذف یک لبه موجود
- معکوس کردن لبه (reverse edge): تغییر جهت یک لبه موجود، به‌شرطی که چرخه ایجاد نشود

گراف جدید با استفاده از تابع امتیازدهی (مانند score_dags) ارزیابی می‌شود. بر اساس نسبت فاکتور بیزی (Bayes factor) و نرخ پذیرش، گراف جدید پذیرفته یا رد می‌شود.

**۳. دوره Burn-in**
در مراحل اولیه (burn-in)، نمونه‌ها ذخیره نمی‌شوند تا زنجیره به حالت پایدار برسد.

**۴. جمع‌آوری نمونه‌ها**
پس از burn-in، گراف‌های نمونه‌برداری شده ذخیره می‌شوند تا توزیع پسین گراف‌ها تخمین زده شود.

**۵. تشخیص همگرایی**
نرخ پذیرش (accept_ratio) به‌عنوان یک معیار خام برای بررسی همگرایی زنجیره استفاده می‌شود. نرخ پذیرش ایده‌آل معمولاً بین ۰.۲ تا ۰.۴ است.

### توابع کمکی مرتبط

**score_dags.m**
- وظیفه: محاسبه امتیاز (score) برای یک یا چند DAG با استفاده از توابع امتیازدهی مانند BDeu یا BIC
- کاربرد: ارزیابی گراف‌های پیشنهادی در هر مرحله از MCMC

**mcmc_sample_to_hist.m**
- وظیفه: تبدیل گراف‌های نمونه‌برداری شده به هیستوگرام (توزیع تجربی پسین)
- کاربرد: تحلیل توزیع گراف‌های نمونه‌برداری شده برای ارزیابی کیفیت نمونه‌برداری

**mk_all_dags.m**
- وظیفه: تولید تمام DAG‌های ممکن برای تعداد مشخصی گره (برای شبکه‌های کوچک)
- کاربرد: برای مقایسه توزیع پسین تجربی با توزیع پسین واقعی در شبکه‌های کوچک

**bic_score_family.m** و **dirichlet_score_family.m**
- وظیفه: محاسبه امتیاز BIC و BDeu برای یک گره و والدین آن
- کاربرد: استفاده در تابع score_dags برای امتیازدهی به گراف‌ها

## بهبودهای اعمال شده

 ۱. افزایش تعداد نمونه‌ها و Burn-in
تعداد نمونه‌ها به ۵۰۰۰ و دوره burn-in به ۲۰۰۰ افزایش یافته تا همگرایی بهتری حاصل شود. این تغییر به کاهش تأثیر تصادفی بودن اولیه و بهبود کیفیت نمونه‌برداری کمک می‌کند.

 ۲. استفاده از تابع امتیازدهی بیزی (Bayesian Score)
به‌جای BIC، از امتیاز بیزی (BDeu) به‌طور پیش‌فرض استفاده شده است، که برای داده‌های کوچک‌تر و متغیرهای با احتمال پایین مناسب‌تر است.

 ۳. مقداردهی اولیه با دانش پیشین
گراف اولیه با لبه‌های شناخته شده شبکه (مانند Asia Tuberculosis Network) مقداردهی شده تا کاوش به ساختارهای محتمل‌تر هدایت شود.

 ۴. اعمال محدودیت حداکثر والدین
محدودیت max_parents=4 برای هر دو روش MCMC و Gibbs Sampling اضافه شده تا از ایجاد گراف‌های بیش از حد پیچیده جلوگیری شود.

 ۵. بهینه‌سازی محاسباتی
استفاده از کش کردن (@lru_cache) برای توابع امتیازدهی (_score_family) جهت کاهش محاسبات تکراری و پیاده‌سازی تشخیص چرخه سریع‌تر با استفاده از DFS بدون وابستگی به کتابخانه‌های خارجی.

 ۶. شبیه‌سازی آنیلینگ (Simulated Annealing)
افزودن برنامه خنک‌سازی (cooling schedule) به MCMC برای بهبود کاوش در مراحل اولیه و همگرایی به ساختارهای بهینه در مراحل بعدی.

## مقایسه با نسخه اصلی BNT

### محدودیت‌های نسخه اصلی

**۱. تعداد نمونه‌های کم:** نسخه اصلی از تعداد نمونه‌های کمی (۱۰۰ نمونه و ۱۰ burn-in) استفاده می‌کرد، که برای شبکه‌های پیچیده کافی نبود.

**۲. عدم استفاده از دانش پیشین:** نسخه اصلی گراف اولیه را به‌صورت تصادفی یا خالی مقداردهی می‌کرد، که می‌توانست به کاوش ناکارآمد منجر شود.

**۳. عدم بهینه‌سازی محاسباتی:** نسخه اصلی فاقد تکنیک‌هایی مانند کش کردن یا موازی‌سازی بود.

**۴. عدم پشتیبانی از Simulated Annealing:** نسخه اصلی از یک رویکرد استاندارد Metropolis-Hastings استفاده می‌کرد، بدون بهینه‌سازی‌های پیشرفته‌تر.

### بهبودهای حاصل شده

با بهبودهایی مانند افزایش تعداد نمونه‌ها و استفاده از دانش پیشین، انتظار می‌رود دقت (Precision) و یادآوری (Recall) نسبت به نسخه اصلی بهبود یابد. همچنین، با افزودن کش کردن و بهینه‌سازی‌ها، زمان اجرا کاهش می‌یابد.

## تحلیل عملکرد و محدودیت‌ها

### عملکرد بهبود یافته

**۱. دقت بهتر:** با بهبودهای اعمال شده، دقت و یادآوری نسبت به نسخه اصلی بهبود می‌یابد.

**۲. سرعت بیشتر:** با افزودن کش کردن و بهینه‌سازی‌ها، زمان اجرا کاهش می‌یابد، اما همچنان برای شبکه‌های بزرگ (بیش از ۱۰ گره) ممکن است کند باشد.

**۳. پایداری بهتر:** استفاده از Simulated Annealing و دانش پیشین باعث می‌شود گراف‌های نمونه‌برداری شده به ساختار واقعی نزدیک‌تر شوند.

### محدودیت‌های باقی‌مانده

**۱. مقیاس‌پذیری:** برای شبکه‌های با تعداد گره‌های زیاد، زمان همگرایی طولانی است.

**۲. داده‌های گسسته:** این روش فقط برای متغیرهای گسسته طراحی شده و از متغیرهای پیوسته پشتیبانی نمی‌کند، مگر با گسسته‌سازی.

**۳. نیاز به تنظیم پارامترها:** انتخاب مناسب nsamples، burnin و تابع امتیازدهی نیازمند تجربه است.

## پیشنهادات برای بهبودهای آینده

 ۱. پشتیبانی از داده‌های مخفی
افزودن قابلیت‌هایی مانند الگوریتم‌های EM برای پشتیبانی از متغیرهای مخفی.

 ۲. موازی‌سازی
استفاده از کتابخانه‌های موازی MATLAB برای کاهش زمان اجرا و بهبود مقیاس‌پذیری.

 ۳. ادغام با روش‌های دیگر
ترکیب MCMC با روش‌های ابتکاری مانند PC algorithm برای مقداردهی اولیه بهتر.

 ۴. تشخیص همگرایی پیشرفته‌تر
استفاده از معیارهای همگرایی پیشرفته‌تر مانند Gelman-Rubin statistic به‌جای نرخ پذیرش ساده.

## نتیجه‌گیری

روش MCMC برای یادگیری ساختار شبکه‌های بیزی ابزار قدرتمندی برای تحلیل روابط پیچیده بین متغیرها است. با وجود محدودیت‌هایی در مقیاس‌پذیری و نوع داده‌ها، بهبودهای اعمال شده عملکرد آن را به‌طور قابل‌توجهی افزایش داده‌اند. این روش برای کاربردهای تحقیقاتی و تحلیل داده‌های متوسط‌الحجم بسیار مفید است.

 [بعدی](section4-2.qmd)
